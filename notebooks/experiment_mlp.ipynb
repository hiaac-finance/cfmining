{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from cfmining.algorithms import P2CE\n",
    "from cfmining.predictors import GeneralClassifier_Shap, GeneralClassifier\n",
    "from cfmining.action_set import ActionSet\n",
    "from cfmining.baselines import Bruteforce, MAPOCAM, Nice, Dice\n",
    "from cfmining.criteria import *\n",
    "\n",
    "from experiments_helper import run_experiments, format_df_table, summarize_results, get_data_model, get_action_set\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_changes = 3\n",
    "objective = \"abs_diff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:44<00:00,  5.69s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:37<00:00,  1.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:32<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in [\n",
    "    \"german\",\n",
    "    \"taiwan\", \n",
    "    \"adult\"\n",
    "    ]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"MLPClassifier\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "    action_set = get_action_set(dataset, X_train, default_step_size=0.05)\n",
    "\n",
    "    model_wrap = GeneralClassifier_Shap(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "        shap_explainer=\"deep_pipe\",\n",
    "    )\n",
    "\n",
    "    method = P2CE(\n",
    "        action_set = action_set,\n",
    "        classifier = model_wrap,\n",
    "        compare = objective,\n",
    "        max_changes = max_changes if dataset_name != \"taiwan\" else 3,\n",
    "        outlier_contamination = dataset.outlier_contamination,\n",
    "        estimate_outlier=True,\n",
    "        time_limit=np.inf,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals=individuals,\n",
    "        model=model_wrap,\n",
    "        output_file=f\"../results/mlp/{dataset}/p2ce_deep_{objective}.csv\"\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▌                                                                                                                                                              | 2/50 [00:14<04:50,  6.06s/it]"
     ]
    }
   ],
   "source": [
    "for dataset_name in [\n",
    "    \"german\", \n",
    "    \"taiwan\", \n",
    "    \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"MLPClassifier\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "    action_set = get_action_set(dataset, X_train, default_step_size=0.05)\n",
    "    for feat in action_set:\n",
    "        feat.flip_direction = 1\n",
    "        feat.update_grid()\n",
    "\n",
    "    model_wrap = GeneralClassifier(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "    )\n",
    "\n",
    "    method = MAPOCAM(\n",
    "        action_set = action_set,\n",
    "        model = model_wrap,\n",
    "        criteria = objective,\n",
    "        max_changes = max_changes,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals=individuals,\n",
    "        model=model_wrap,\n",
    "        output_file=f\"../results/mlp/{dataset_name}/mapocam_{objective}.csv\"\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"MLPClassifier\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "\n",
    "    model_wrap = GeneralClassifier(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "    )\n",
    "\n",
    "    method = Dice(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        model,\n",
    "        n_cfs = 1,\n",
    "        mutable_features = dataset.mutable_features,\n",
    "        continuous_features = dataset.continuous_features,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals = individuals,\n",
    "        model = model_wrap,\n",
    "        output_file=f\"../results/mlp/{dataset_name}/dice.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 29.36it/s]\n",
      "PermutationExplainer explainer: 101it [00:11,  1.28it/s]                                                                                                                                                 \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 19.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 28.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"MLPClassifier\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "\n",
    "    model_wrap = GeneralClassifier(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "    )\n",
    "\n",
    "    method = Nice(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        model = model,\n",
    "        cat_features = dataset.categoric_features,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals = individuals,\n",
    "        model = model_wrap,\n",
    "        output_file=f\"../results/mlp/{dataset_name}/nice.csv\"\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = [\"p2ce_deep_abs_diff\", \"mapocam_abs_diff\", \"dice\", \"nice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"taiwan\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"adult\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [18:59<00:00, 22.80s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:47<00:00,  1.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:38<00:00,  6.76s/it]\n"
     ]
    }
   ],
   "source": [
    "max_changes = 3\n",
    "for dataset_name in [\n",
    "    \"german\",\n",
    "    \"taiwan\", \n",
    "    \"adult\"\n",
    "    ]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"MLPClassifier\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "    action_set = get_action_set(dataset, X_train, default_step_size=0.05)\n",
    "\n",
    "    model_wrap = GeneralClassifier_Shap(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "        shap_explainer=\"deep_pipe\",\n",
    "    )\n",
    "\n",
    "    #setting multiple criteria\n",
    "    range_calc = RangeCalculator(action_set)\n",
    "    perc_calc = PercentileCalculator(action_set = action_set)\n",
    "\n",
    "    def compare_call(pivot):\n",
    "        criteria_list = [\n",
    "            MaxDistCriterion(\n",
    "                pivot,\n",
    "                range_calc,\n",
    "            ),\n",
    "            NumberChangesCriterion(pivot),\n",
    "            PercentileCriterion(\n",
    "                pivot,\n",
    "                perc_calc,\n",
    "            )\n",
    "        ]\n",
    "        return MultiCriterion(criteria_list, pivot)\n",
    "\n",
    "    method = P2CE(\n",
    "        action_set = action_set,\n",
    "        classifier = model_wrap,\n",
    "        compare = compare_call,\n",
    "        max_changes = max_changes,\n",
    "        outlier_contamination= dataset.outlier_contamination,\n",
    "        estimate_outlier=True,\n",
    "        time_limit=np.inf,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals=individuals,\n",
    "        model=model_wrap,\n",
    "        output_file=f\"../results/mlp/{dataset}/p2ce_deep_multi.csv\"\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [41:21<00:00, 49.63s/it]\n",
      "PermutationExplainer explainer: 101it [00:12,  1.55it/s]                                                                                                                                                 \n",
      " 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 42/50 [1:23:26<14:49, 111.18s/it]"
     ]
    }
   ],
   "source": [
    "max_changes = 3\n",
    "for dataset_name in [\n",
    "    \"german\", \n",
    "    \"taiwan\", \n",
    "    \"adult\"\n",
    "    ]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"MLPClassifier\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "    action_set = get_action_set(dataset, X_train, default_step_size=0.05)\n",
    "    for feat in action_set:\n",
    "        feat.flip_direction = 1\n",
    "        feat.update_grid()\n",
    "\n",
    "    model_wrap = GeneralClassifier(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "    )\n",
    "\n",
    "    #setting multiple criteria\n",
    "    range_calc = RangeCalculator(action_set)\n",
    "    perc_calc = PercentileCalculator(action_set = action_set)\n",
    "\n",
    "    def compare_call(pivot):\n",
    "        criteria_list = [\n",
    "            MaxDistCriterion(\n",
    "                pivot,\n",
    "                range_calc,\n",
    "            ),\n",
    "            NumberChangesCriterion(pivot),\n",
    "            PercentileCriterion(\n",
    "                pivot,\n",
    "                perc_calc,\n",
    "            )\n",
    "        ]\n",
    "        return MultiCriterion(criteria_list, pivot)\n",
    "    \n",
    "    method = MAPOCAM(\n",
    "        action_set = action_set,\n",
    "        model = model_wrap,\n",
    "        criteria = compare_call,\n",
    "        max_changes = max_changes,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals=individuals,\n",
    "        model=model_wrap,\n",
    "        output_file=f\"../results/mlp/{dataset_name}/mapocam_multi.csv\"\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"MLPClassifier\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "\n",
    "    n_cfs = 4\n",
    "\n",
    "\n",
    "    model_wrap = GeneralClassifier(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "    )\n",
    "\n",
    "\n",
    "    method = Dice(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        model,\n",
    "        n_cfs = n_cfs,\n",
    "        mutable_features = dataset.mutable_features,\n",
    "        continuous_features = dataset.continuous_features,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals = individuals,\n",
    "        model = model_wrap,\n",
    "        output_file=f\"../results/mlp/{dataset_name}/dice_multi.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german\"\n",
    "results = []\n",
    "for method in [\"p2ce_deep_multi\", \"mapocam_multi\", \"dice_multi\"]:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"taiwan\"\n",
    "results = []\n",
    "for method in [\"p2ce_deep_multi\", \"mapocam_multi\", \"dice_multi\"]:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"adult\"\n",
    "results = []\n",
    "for method in [\"p2ce_deep_multi\", \"mapocam_multi\", \"dice_multi\"]:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
