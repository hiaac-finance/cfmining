{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "from experiments_helper import format_df_table, summarize_results, get_data_model, summarize_results_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def methods_naming(name):\n",
    "    if \"p2ce\" in name:\n",
    "        return \"P$^2$CE\"\n",
    "    elif \"mapocam\" in name:\n",
    "        return \"MAPOCAM\"\n",
    "    elif \"dice\" in name:\n",
    "        return \"DICE\"\n",
    "    elif \"nice\" in name:\n",
    "        return \"NICE\"\n",
    "    else:\n",
    "        return name\n",
    "    \n",
    "\n",
    "def methods_coloring(name):\n",
    "    if \"p2ce\" in name:\n",
    "        return \"#66c2a5\"\n",
    "    elif \"mapocam\" in name:\n",
    "        return \"#fc8d62\"\n",
    "    elif \"dice\" in name:\n",
    "        return \"#80b1d3\"\n",
    "    elif \"nice\" in name:\n",
    "        return \"#984ea3\"\n",
    "    else:\n",
    "        return \"#ff0000\"\n",
    "    \n",
    "def dataset_naming(name):\n",
    "    if name == \"german\":\n",
    "        return \"German Credit\"\n",
    "    elif name == \"taiwan\":\n",
    "        return \"Taiwan\"\n",
    "    elif name == \"adult\":\n",
    "        return \"Adult\"\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test(results, axs):\n",
    "    outliers_ = []\n",
    "    method_list = results.method.unique()\n",
    "    min_x, max_x, min_y, max_y = np.inf, -np.inf, np.inf, -np.inf\n",
    "    for method in method_list:\n",
    "        results_r = results[results.method == method]\n",
    "        x_mean = results_r.time.mean()\n",
    "        y_mean = results_r.costs.mean()\n",
    "        outliers_.append(results_r.outlier.mean())\n",
    "\n",
    "        min_x = min(min_x, x_mean)\n",
    "        max_x = max(max_x, x_mean)\n",
    "        min_y = min(min_y, y_mean)\n",
    "        max_y = max(max_y, y_mean)\n",
    "\n",
    "        x_05 = x_mean - np.quantile(results_r.time, 0.05)\n",
    "        x_95 = np.quantile(results_r.time, 0.95) - x_mean\n",
    "        y_05 = y_mean - np.quantile(results_r.costs, 0.05)\n",
    "        y_95 = np.quantile(results_r.costs, 0.95) - y_mean\n",
    "\n",
    "\n",
    "        axs[0].scatter(\n",
    "            x_mean, \n",
    "            y_mean, \n",
    "            label = methods_naming(method), \n",
    "            c = methods_coloring(method),\n",
    "            zorder = 100 if \"p2ce\" in method else 2,\n",
    "        )\n",
    "        axs[0].errorbar(\n",
    "            [x_mean],\n",
    "            [y_mean],\n",
    "            xerr = [[x_05], [x_95]],\n",
    "            yerr = [[y_05], [y_95]],\n",
    "            label = methods_naming(method),\n",
    "            c = methods_coloring(method),\n",
    "            zorder = 100 if \"p2ce\" in method else 2,\n",
    "        )\n",
    "\n",
    "    x_pad = (max_x - min_x) * 0.1\n",
    "    y_pad = (max_y - min_y) * 0.1\n",
    "    #axs[0].set_xlim(min_x - x_pad, max_x + x_pad)\n",
    "    #axs[0].set_ylim(min_y - y_pad, max_y + y_pad)\n",
    "\n",
    "    handles = [\n",
    "        Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker = \"o\",\n",
    "            color = \"w\",\n",
    "            markerfacecolor =  methods_coloring(name),\n",
    "            markersize = 10,\n",
    "            label = methods_naming(name),\n",
    "        ) for name in method_list\n",
    "    ]\n",
    "    axs[0].set_xlabel(\"Time (s)\")\n",
    "    axs[0].set_ylabel(\"Average Continuous Dist.\")\n",
    "\n",
    "\n",
    "    axs[1].barh(\n",
    "        [methods_naming(name) for name in method_list],\n",
    "        [o * 100 for o in outliers_],\n",
    "        color = [methods_coloring(name) for name in method_list],\n",
    "    )\n",
    "    axs[1].set_xlabel(\"% Outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (13, 5), layout = \"constrained\")\n",
    "axs = fig.subplots(nrows = 2, ncols = 6, height_ratios=[1, 0.6])\n",
    "\n",
    "for i, dataset_name in enumerate([\"german\", \"taiwan\", \"adult\"]):\n",
    "    for j, model in enumerate([\"lgbm\", \"mlp\"]):\n",
    "        results = []\n",
    "        if model == \"lgbm\":\n",
    "            method_list = [\"p2ce_tree_abs_diff\", \"mapocam_tree_abs_diff\", \"dice\", \"nice\"]\n",
    "        else:\n",
    "            method_list = [\"p2ce_deep_abs_diff\", \"mapocam_abs_diff\", \"dice\", \"nice\"]\n",
    "\n",
    "        for method in method_list:\n",
    "            try:\n",
    "                results_cur = pd.read_csv(f\"../results/{model}/{dataset_name}/{method}.csv\")\n",
    "                results_cur = summarize_results(results_cur, dataset_name)\n",
    "\n",
    "                if \"p2ce\" in method:\n",
    "                    method = \"p2ce_abs_diff\"\n",
    "                if \"mapocam\" in method:\n",
    "                    method = \"mapocam_abs_diff\"\n",
    "                    \n",
    "                results_cur[\"method\"] = method\n",
    "                results.append(results_cur)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        results = pd.concat(results)\n",
    "        results[\"costs\"] = results[\"abs_diff_costs\"]\n",
    "        axs_ = [axs[0][j * 3 + i], axs[1][j * 3 + i]]\n",
    "        plot_test(results, axs_)\n",
    "\n",
    "        axs[0][j * 3 + i].set_title(f\"{dataset_naming(dataset_name)} - {model.upper()}\")\n",
    "\n",
    "for i in range(1, 6):\n",
    "    axs[1][i].set_yticklabels([])\n",
    "\n",
    "plt.suptitle(\"Comparison with 1 Objective\")\n",
    "plt.savefig(\"../figures/percentile_results.pdf\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the legend separately\n",
    "\n",
    "fig = plt.figure()\n",
    "handles = [\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker = \"o\",\n",
    "        color = \"w\",\n",
    "        markerfacecolor =  methods_coloring(name),\n",
    "        markersize = 10,\n",
    "        label = methods_naming(name),\n",
    "    ) for name in results.method.unique()\n",
    "]\n",
    "handles = handles[::-1]\n",
    "plt.axis(\"off\")\n",
    "plt.legend(handles=handles, ncol = len(handles), loc='upper center', bbox_to_anchor=(0.5, -0.4),)\n",
    "plt.savefig(\"../figures/percentile_legend.pdf\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comaparison with multiple objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german\"\n",
    "method_list = [\"mapocam_tree_multi\", \"p2ce_tree_multi\", \"dice_multi\"]\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"taiwan\"\n",
    "method_list = [\"mapocam_tree_multi\", \"p2ce_tree_multi\", \"dice_multi\"]\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"adult\"\n",
    "method_list = [\"mapocam_tree_multi\", \"p2ce_tree_multi\", \"dice_multi\"]\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german\"\n",
    "method_list = [\"mapocam_multi\", \"p2ce_deep_multi\", \"dice_multi\"]\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"taiwan\"\n",
    "method_list = [\"mapocam_multi\", \"p2ce_deep_multi\", \"dice_multi\"]\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"adult\"\n",
    "method_list = [\"mapocam_multi\", \"p2ce_deep_multi\", \"dice_multi\"]\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/mlp/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygmo import hypervolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dominated_solutions(A):\n",
    "    \"\"\"From a list of costs, keep only the non-dominated solutions.\"\"\"\n",
    "    non_dominated = []\n",
    "    for i, s1 in enumerate(A):\n",
    "        dominated = False\n",
    "        for j, s2 in enumerate(A):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if all(s2 <= s1):\n",
    "                if (s1 - s2).sum() < 1e-8:\n",
    "                    # are the same solution\n",
    "                    continue\n",
    "\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            non_dominated.append(s1)\n",
    "\n",
    "    return non_dominated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments_multi_costs(\n",
    "    dataset_name,\n",
    "    method_name,\n",
    "    model_name,\n",
    "    keep_dominated = False\n",
    "):  \n",
    "    \"\"\"Get the costs of the experiments for a multi-objective method.\n",
    "    It will return an list of numpy arrays, where each array contains the costs of the solutions for an individual.\n",
    "    \"\"\"\n",
    "    results = pd.read_csv(f\"../results/{model_name}/{dataset_name}/{method_name}.csv\")\n",
    "    results = summarize_results_multi(results, dataset_name)\n",
    "    costs = results[[\"abs_diff_costs\", \"max_dist_costs\", \"n_changes\"]].values\n",
    "    costs = costs.tolist()\n",
    "    costs = [np.array(list(zip(*c))) for c in costs]\n",
    "    if not keep_dominated:\n",
    "        costs = [remove_dominated_solutions(c) for c in costs]\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for dataset in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    costs = {}\n",
    "    method_list = [\"p2ce_tree_multi\", \"mapocam_tree_multi\",  \"dice_multi\"]\n",
    "    for method in method_list:\n",
    "        costs[method] = get_experiments_multi_costs(dataset, method, \"lgbm\", keep_dominated = False)\n",
    "\n",
    "\n",
    "    # get maximum cost for each objective\n",
    "    max_costs = np.ones(len(costs[method][0][0])) * -np.inf\n",
    "\n",
    "    for method in method_list:\n",
    "        for i in range(50): # for each individual\n",
    "            if len(costs[method][i]) == 0:\n",
    "                continue\n",
    "            max_costs = np.maximum(max_costs, np.max(costs[method][i], axis = 0))\n",
    "\n",
    "    \n",
    "    # calculate hypervolume of each method\n",
    "    for method in method_list:\n",
    "        for i in range(50):\n",
    "            if len(costs[method][i]) == 0:\n",
    "                hv = 0\n",
    "            else:\n",
    "                costs_ = costs[method][i]\n",
    "                costs_ /= max_costs\n",
    "                hv = hypervolume(costs_).compute(np.ones(len(max_costs)))\n",
    "\n",
    "            results.append([dataset, method, i, hv])\n",
    "results = pd.DataFrame(results, columns = [\"dataset\", \"method\", \"individual\", \"hv\"])\n",
    "\n",
    "def make_table(df):\n",
    "    hv_mean = df[\"hv\"].mean().round(2)\n",
    "    hv_std = df[\"hv\"].std().round(2)\n",
    "    return f\"{hv_mean} ($\\pm$ {hv_std})\"\n",
    "results.groupby([\"dataset\", \"method\"]).apply(make_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for dataset in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    costs = {}\n",
    "    method_list = [\"p2ce_deep_multi\", \"mapocam_multi\",  \"dice_multi\"]\n",
    "    for method in method_list:\n",
    "        costs[method] = get_experiments_multi_costs(dataset, method, \"mlp\", keep_dominated = False)\n",
    "\n",
    "\n",
    "    # get maximum cost for each objective\n",
    "    max_costs = np.ones(len(costs[method][0][0])) * -np.inf\n",
    "\n",
    "    for method in method_list:\n",
    "        for i in range(50): # for each individual\n",
    "            if len(costs[method][i]) == 0:\n",
    "                continue\n",
    "            max_costs = np.maximum(max_costs, np.max(costs[method][i], axis = 0))\n",
    "\n",
    "    \n",
    "    # calculate hypervolume of each method\n",
    "    for method in method_list:\n",
    "        for i in range(50):\n",
    "            if len(costs[method][i]) == 0:\n",
    "                hv = 0\n",
    "            else:\n",
    "                costs_ = costs[method][i]\n",
    "                costs_ /= max_costs\n",
    "                hv = hypervolume(costs_).compute(np.ones(len(max_costs)))\n",
    "\n",
    "            results.append([dataset, method, i, hv])\n",
    "results = pd.DataFrame(results, columns = [\"dataset\", \"method\", \"individual\", \"hv\"])\n",
    "\n",
    "def make_table(df):\n",
    "    hv_mean = df[\"hv\"].mean().round(2)\n",
    "    hv_std = df[\"hv\"].std().round(2)\n",
    "    return f\"{hv_mean} ($\\pm$ {hv_std})\"\n",
    "results.groupby([\"dataset\", \"method\"]).apply(make_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example comparison of Counterfactual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "dataset_name = \"adult\"\n",
    "SEED = 0\n",
    "dataset, X_train, _, model, outlier_detection, individuals = get_data_model(dataset_name, \"MLPClassifier\")\n",
    "individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "\n",
    "# get the solution of individual i for each method\n",
    "method_list = [\"p2ce_deep_multi\", \"mapocam_multi\", \"dice_multi\"]\n",
    "df_temp = []\n",
    "for method in method_list:\n",
    "    results = pd.read_csv(f\"../results/mlp/{dataset_name}/{method}.csv\")\n",
    "\n",
    "    solutions = literal_eval(results[\"solutions\"].iloc[i])\n",
    "    for s in solutions:\n",
    "        s_df = pd.DataFrame([s], columns = X_train.columns.tolist())\n",
    "        extra_columns = [\n",
    "            method,\n",
    "            outlier_detection.predict(np.array([s]))[0],\n",
    "            model.predict_proba(s_df)[0, 1],\n",
    "        ]\n",
    "        df_temp.append(s + extra_columns)\n",
    "\n",
    "extra_columns = [\n",
    "    \"individual\",\n",
    "    1,\n",
    "    model.predict_proba(individuals.iloc[i:i+1])[0, 1],\n",
    "]\n",
    "df_temp.append(\n",
    "    individuals.iloc[i].tolist() + extra_columns\n",
    ")\n",
    "df_temp = df_temp[::-1]\n",
    "df_temp = pd.DataFrame(df_temp, columns = X_train.columns.tolist() + [\"method\", \"outlier\", \"pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_unique_value_cols = []\n",
    "for col in df_temp.columns:\n",
    "    if len(df_temp[col].unique()) > 1:\n",
    "        not_unique_value_cols.append(col)\n",
    "df_temp = df_temp[not_unique_value_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
