{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from cfmining.algorithms import P2CE\n",
    "from cfmining.predictors import GeneralClassifier_Shap, GeneralClassifier, TreeClassifier\n",
    "from cfmining.action_set import ActionSet\n",
    "from cfmining.baselines import Bruteforce, MAPOCAM, Nice, Dice\n",
    "from cfmining.criteria import *\n",
    "\n",
    "from experiments_helper import get_data_model, run_experiments, format_df_table, summarize_results, get_action_set, summarize_results_multi\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_changes = 3\n",
    "objective = \"abs_diff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:21<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:25<00:00,  1.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"LGBMClassifier_simple\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "    action_set = get_action_set(dataset, X_train, default_step_size=0.05)\n",
    "\n",
    "    model_wrap = GeneralClassifier_Shap(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "        shap_explainer=\"tree\",\n",
    "    )\n",
    "\n",
    "    method = P2CE(\n",
    "        action_set = action_set,\n",
    "        classifier = model_wrap,\n",
    "        compare = objective,\n",
    "        max_changes = max_changes,\n",
    "        outlier_contamination = dataset.outlier_contamination,\n",
    "        estimate_outlier=True,\n",
    "        time_limit=np.inf,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals=individuals,\n",
    "        model=model_wrap,\n",
    "        output_file=f\"../results/lgbm/{dataset}/p2ce_tree_{objective}.csv\"\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:13<00:00,  1.47s/it]\n",
      "PermutationExplainer explainer: 101it [00:11,  1.14it/s]                                                                                                                                                 \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [03:30<00:00,  4.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"LGBMClassifier_simple\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "    action_set = get_action_set(dataset, X_train, default_step_size=0.05)\n",
    "    for feat in action_set:\n",
    "        feat.flip_direction = 1\n",
    "        feat.update_grid()\n",
    "\n",
    "    model_wrap = TreeClassifier(\n",
    "        classifier = model,\n",
    "        X = X_train,\n",
    "        y = Y_train,\n",
    "        use_predict_max = True,\n",
    "        clf_type = \"lightgbm\",\n",
    "    )\n",
    "\n",
    "    method = MAPOCAM(\n",
    "        action_set = action_set,\n",
    "        model = model_wrap,\n",
    "        criteria = objective,\n",
    "        max_changes = max_changes,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals=individuals,\n",
    "        model=model_wrap,\n",
    "        output_file=f\"../results/lgbm/{dataset_name}/mapocam_tree_{objective}.csv\"\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"LGBMClassifier_simple\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "\n",
    "    model_wrap = GeneralClassifier(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "    )\n",
    "\n",
    "    method = Nice(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        model = model,\n",
    "        cat_features = dataset.categoric_features,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals = individuals,\n",
    "        model = model_wrap,\n",
    "        output_file=f\"../results/lgbm/{dataset_name}/nice.csv\"\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"LGBMClassifier_simple\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "\n",
    "    model_wrap = GeneralClassifier(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "    )\n",
    "\n",
    "\n",
    "    method = Dice(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        model,\n",
    "        n_cfs = 1,\n",
    "        mutable_features = dataset.mutable_features,\n",
    "        continuous_features = dataset.continuous_features,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals = individuals,\n",
    "        model = model_wrap,\n",
    "        output_file=f\"../results/lgbm/{dataset_name}/dice.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = [\"p2ce_tree_abs_diff\", \"mapocam_tree_abs_diff\", \"mapocam_abs_diff\", \"dice\", \"nice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"taiwan\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"adult\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_changes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:33<00:00,  1.88s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:21<00:00,  1.63s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:07<00:00,  6.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in [\n",
    "    \"german\",\n",
    "    \"taiwan\", \n",
    "    \"adult\"\n",
    "    ]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"LGBMClassifier_simple\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "    action_set = get_action_set(dataset, X_train, default_step_size=0.05)\n",
    "\n",
    "    model_wrap = GeneralClassifier_Shap(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "        shap_explainer=\"tree\",\n",
    "    )\n",
    "\n",
    "    #setting multiple criteria\n",
    "    range_calc = RangeCalculator(action_set)\n",
    "    def compare_call(pivot):\n",
    "        criteria_list = [\n",
    "            MaxDistCriterion(\n",
    "                pivot,\n",
    "                range_calc,\n",
    "            ),\n",
    "            NumberChangesCriterion(pivot),\n",
    "            AbsDiffCriterion(pivot, range_calc),\n",
    "        ]\n",
    "        return MultiCriterion(criteria_list, pivot)\n",
    "\n",
    "    method = P2CE(\n",
    "        action_set = action_set,\n",
    "        classifier = model_wrap,\n",
    "        compare = compare_call,\n",
    "        max_changes = max_changes,\n",
    "        outlier_contamination= dataset.outlier_contamination,\n",
    "        estimate_outlier=True,\n",
    "        time_limit=np.inf,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals=individuals,\n",
    "        model=model_wrap,\n",
    "        output_file=f\"../results/lgbm/{dataset}/p2ce_tree_multi.csv\"\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:51<00:00,  2.23s/it]\n",
      "PermutationExplainer explainer: 101it [00:12,  1.66it/s]                                                                                                                                                 \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [06:38<00:00,  7.96s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:45<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in [\n",
    "    \"german\", \n",
    "    \"taiwan\", \n",
    "    \"adult\"\n",
    "    ]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"LGBMClassifier_simple\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "    action_set = get_action_set(dataset, X_train, default_step_size=0.05)\n",
    "    for feat in action_set:\n",
    "        feat.flip_direction = 1\n",
    "        feat.update_grid()\n",
    "\n",
    "    model_wrap = TreeClassifier(\n",
    "        classifier = model,\n",
    "        X = X_train,\n",
    "        y = Y_train,\n",
    "        use_predict_max = True,\n",
    "        clf_type = \"lightgbm\",\n",
    "    )\n",
    "\n",
    "    #setting multiple criteria\n",
    "    range_calc = RangeCalculator(action_set)\n",
    "\n",
    "    def compare_call(pivot):\n",
    "        criteria_list = [\n",
    "            MaxDistCriterion(\n",
    "                pivot,\n",
    "                range_calc,\n",
    "            ),\n",
    "            NumberChangesCriterion(pivot),\n",
    "            AbsDiffCriterion(pivot, range_calc),\n",
    "        ]\n",
    "        return MultiCriterion(criteria_list, pivot)\n",
    "    \n",
    "    method = MAPOCAM(\n",
    "        action_set = action_set,\n",
    "        model = model_wrap,\n",
    "        criteria = compare_call,\n",
    "        max_changes = max_changes,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals=individuals,\n",
    "        model=model_wrap,\n",
    "        output_file=f\"../results/lgbm/{dataset_name}/mapocam_tree_multi.csv\"\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"german\", \"taiwan\", \"adult\"]:\n",
    "    dataset, X_train, Y_train, model, outlier_detection, individuals = get_data_model(dataset_name, \"LGBMClassifier_simple\")\n",
    "    individuals = individuals.sample(n = 50, random_state=SEED)\n",
    "    outlier_detection.contamination = dataset.outlier_contamination\n",
    "\n",
    "    n_cfs = 4\n",
    "\n",
    "\n",
    "    model_wrap = GeneralClassifier(\n",
    "        model,\n",
    "        outlier_detection,\n",
    "        X_train,\n",
    "    )\n",
    "\n",
    "\n",
    "    method = Dice(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        model,\n",
    "        n_cfs = n_cfs,\n",
    "        mutable_features = dataset.mutable_features,\n",
    "        continuous_features = dataset.continuous_features,\n",
    "    )\n",
    "\n",
    "    run_experiments(\n",
    "        method,\n",
    "        individuals = individuals,\n",
    "        model = model_wrap,\n",
    "        output_file=f\"../results/lgbm/{dataset_name}/dice_multi.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = [\"p2ce_tree_multi\", \"mapocam_multi\", \"mapocam_tree_multi\", \"dice_multi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"german\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"taiwan\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"adult\"\n",
    "results = []\n",
    "for method in method_list:\n",
    "    results_cur = pd.read_csv(f\"../results/lgbm/{dataset}/{method}.csv\")\n",
    "    results_cur = summarize_results(results_cur, dataset)\n",
    "    results_cur[\"method\"] = method\n",
    "    results.append(results_cur)\n",
    "results = pd.concat(results)\n",
    "format_df_table(results, \"method\", results.columns.tolist()[:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
