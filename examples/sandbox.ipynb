{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "from sklearn import preprocessing, pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.ensemble import IsolationForest\n",
    "from isotree import IsolationForest\n",
    "\n",
    "from cfmining.mip_algorithms import LinearRecourseActions, LinearRecourseActionsMulti\n",
    "from cfmining.algorithms import MAPOCAM, BruteForce, Greedy, MAPOCAM2\n",
    "from cfmining.criteria import PercentileCalculator, PercentileCriterion, PercentileChangesCriterion, NonDomCriterion\n",
    "from cfmining.predictors import MonotoneClassifier, GeneralClassifier, TreeClassifier, LinearClassifier, LinearRule, GeneralClassifier_Shap\n",
    "from cfmining.action_set import ActionSet\n",
    "\n",
    "from results import save_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "data_name = 'german'\n",
    "data_file = os.path.join(data_dir, '%s_processed.csv' % data_name)\n",
    "## load and process data\n",
    "german_df = pd.read_csv(data_file).reset_index(drop=True)\n",
    "german_df = (german_df\n",
    "             .assign(isMale=lambda df: (df['Gender']=='Male').astype(int))\n",
    "             .drop(['PurposeOfLoan', 'Gender', 'OtherLoansAtStore'], axis=1)\n",
    "            )\n",
    "\n",
    "y = german_df['GoodCustomer']\n",
    "# tranform y to [0, 1]\n",
    "y = (y == 1).astype(int)\n",
    "X = german_df.drop('GoodCustomer', axis=1)\n",
    "#X = X[['ForeignWorker', 'Single', 'Age', 'LoanDuration', 'LoanAmount', 'LoanRateAsPercentOfIncome', 'isMale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xts, ytr, yts = train_test_split(X, y, test_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True]), array([640, 260]))\n"
     ]
    }
   ],
   "source": [
    "outlier_detection = IsolationForest(ndim=1, sample_size=256, max_depth=8, ntrees=100, missing_action=\"divide\")\n",
    "outlier_detection.fit(Xtr);\n",
    "print(np.unique(outlier_detection.predict(Xtr) > 0.5, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting ActionSet base parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set_base = ActionSet(X = X)\n",
    "for feat in action_set_base:\n",
    "    if feat.name in ['Age', 'JobClassIsSkilled', 'OwnsHouse', 'isMale', 'JobClassIsSkilled']:\n",
    "        feat.mutable = False\n",
    "        feat.step_direction = 1\n",
    "    if feat.name in ['Single', 'ForeignWorker', 'RentsHouse']:\n",
    "        feat.mutable = False\n",
    "        feat.step_direction = -1\n",
    "    if feat.name in ['LoanDuration', 'LoanAmount', 'LoanRateAsPercentOfIncome', 'NumberOfOtherLoansAtBank', 'MissedPayments',\n",
    "                     'CriticalAccountOrLoansElsewhere', 'OtherLoansAtBank', 'Unemployed', 'YearsAtCurrentJob_lt_1']:\n",
    "        feat.mutable = True\n",
    "        feat.step_direction = -1\n",
    "    if feat.name in ['YearsAtCurrentHome', 'NumberOfLiableIndividuals', 'HasTelephone', 'CheckingAccountBalance_geq_0',\n",
    "                     'CheckingAccountBalance_geq_200', 'SavingsAccountBalance_geq_100', 'SavingsAccountBalance_geq_500',\n",
    "                     'NoCurrentLoan', 'HasCoapplicant', 'HasGuarantor', 'YearsAtCurrentJob_geq_4']:\n",
    "        feat.mutable = True\n",
    "        feat.step_direction = 1\n",
    "    \n",
    "    feat.flip_direction = 1\n",
    "    feat.update_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand = preprocessing.StandardScaler()\n",
    "clf_base = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "clf = pipeline.Pipeline([('std', stand), ('clf', clf_base)])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "  clf, param_grid={'clf__C': np.logspace(-4, 3)},\n",
    "  cv=5,\n",
    "  scoring='roc_auc',\n",
    "  verbose=0\n",
    ")\n",
    "\n",
    "grid.fit(Xtr, ytr)\n",
    "clf_lgr = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "scores = pd.Series(clf_lgr.predict_proba(Xts)[:, 1])\n",
    "denied_individuals = scores.loc[lambda s: s < threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgr_mapocam = MonotoneClassifier(clf_lgr, X=Xtr, y=ytr, threshold=threshold)\n",
    "coefficients = clf_lgr['clf'].coef_[0]/clf_lgr['std'].scale_\n",
    "intercept = clf_lgr['clf'].intercept_[0]-coefficients@clf_lgr['std'].mean_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of estimation of max probability using the two approaches: (SHAP and monotone assumption)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 901it [00:16, 31.69it/s]                          \n"
     ]
    }
   ],
   "source": [
    "clf_lgr_shap_1 = GeneralClassifier_Shap(clf_lgr, X=Xtr, y=ytr, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    }
   ],
   "source": [
    "clf_lgr_shap_2 = GeneralClassifier_Shap(clf_lgr, X=Xtr, y=ytr, threshold=threshold, method_predict_max=\"monotone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_max_1 = []\n",
    "prob_max_2 = []\n",
    "fixed_vars = [0, 1, 2]\n",
    "for i in range(100):\n",
    "    row = Xts.values[i, :]\n",
    "    prob_max_1.append(clf_lgr_shap_1.predict_max(row, fixed_vars=fixed_vars))\n",
    "    prob_max_2.append(clf_lgr_shap_2.predict_max(row, fixed_vars=fixed_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00401614567964137"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_max_1 = np.array(prob_max_1)\n",
    "prob_max_2 = np.array(prob_max_2)\n",
    "np.median(prob_max_1 - prob_max_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing counterfactual parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionSet stats\n",
      "Number of actionable features: 11\n",
      "Mean number of actions per feature: 2.1818181818181817\n",
      "Max number of actions per feature: 4.0\n",
      "Number of combinations: 542575165440\n"
     ]
    }
   ],
   "source": [
    "action_set = copy.deepcopy(action_set_base)\n",
    "action_set['Age'].mutable = False\n",
    "action_set['Age'].update_grid()\n",
    "\n",
    "action_set['LoanDuration'].step_type =\"absolute\"\n",
    "action_set['LoanDuration'].step_size = 6\n",
    "action_set['LoanDuration'].update_grid()\n",
    "\n",
    "action_set['LoanAmount'].step_size = 0.1\n",
    "action_set['LoanAmount'].update_grid()\n",
    "\n",
    "print('ActionSet stats')\n",
    "print('Number of actionable features:', sum([action.actionable for action in action_set]))\n",
    "print('Mean number of actions per feature:', np.nanmean([len(action._grid) if action.actionable else np.nan for action in action_set]))\n",
    "print('Max number of actions per feature:', np.nanmax([len(action._grid) if action.actionable else np.nan for action in action_set]))\n",
    "log_combinations = int(np.prod([len(action._grid) for action in action_set if action_set.actionable]))\n",
    "print('Number of combinations:', log_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "percCalc = PercentileCalculator(action_set=action_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = LinearRecourseActions(action_set, individual, coefficients, intercept, threshold)\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_lgr_results[i] = {}\n",
    "    lp_lgr_results[i]['enum'] = lp\n",
    "    lp_lgr_results[i]['indiv'] = individual\n",
    "    lp_lgr_results[i]['solution'] = np.array([int(s) if act.variable_type=='int' else float(s) for s, act in zip(lp.solution, action_set)])\n",
    "    lp_lgr_results[i]['stats'] = lp.stats\n",
    "    lp_lgr_results[i]['recourse'] = lp.recourse\n",
    "    lp_lgr_results[i]['time'] = lp_time\n",
    "    lp_lgr_results[i]['cost'] = criteria.f(lp_lgr_results[i]['solution']) if not any(np.isnan(lp_lgr_results[i]['solution'])) else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    greedy = Greedy(action_set, individual, clf_lgr_mapocam, criteria)\n",
    "    greedy.fit()\n",
    "    greedy_time = time.perf_counter()-start\n",
    "    \n",
    "    greedy_lgr_results[i] = {}\n",
    "    greedy_lgr_results[i]['solution'] = greedy.solution\n",
    "    greedy_lgr_results[i]['time'] = greedy_time\n",
    "    greedy_lgr_results[i]['cost'] = criteria.f(greedy.solution) if greedy.solution is not None else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 57%|█████▋    | 24/42 [00:00<00:00, 236.39it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "100%|██████████| 42/42 [00:00<00:00, 283.22it/s]\n"
     ]
    }
   ],
   "source": [
    "mapocam_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM(action_set, individual, clf_lgr_mapocam,\n",
    "                      max_changes=float('inf'), compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_lgr_results[i] = {}\n",
    "    mapocam_lgr_results[i]['enum'] = mapocam\n",
    "    mapocam_lgr_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_lgr_results[i]['time'] = mapocam_time\n",
    "    mapocam_lgr_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPOCAM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  3%|▎         | 1/34 [00:00<00:05,  6.40it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 12%|█▏        | 4/34 [00:00<00:02, 12.41it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 18%|█▊        | 6/34 [00:00<00:02, 13.82it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 32%|███▏      | 11/34 [00:00<00:01, 17.48it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 38%|███▊      | 13/34 [00:00<00:01, 17.33it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 44%|████▍     | 15/34 [00:00<00:01, 16.28it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 88%|████████▊ | 30/34 [00:01<00:00, 45.57it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "100%|██████████| 34/34 [00:01<00:00, 30.74it/s]\n"
     ]
    }
   ],
   "source": [
    "mapocam2_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM2(\n",
    "            action_set, \n",
    "            individual, \n",
    "            clf_lgr_shap_1, \n",
    "            #outlier_detection,\n",
    "            max_changes=float('inf'), \n",
    "            compare=criteria\n",
    "    )\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam2_lgr_results[i] = {}\n",
    "    mapocam2_lgr_results[i]['enum'] = mapocam\n",
    "    mapocam2_lgr_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam2_lgr_results[i]['time'] = mapocam_time\n",
    "    mapocam2_lgr_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')\n",
    "    mapocam2_lgr_results[i][\"prob_max_counter\"] = mapocam.prob_max_counter\n",
    "    mapocam2_lgr_results[i][\"outlier_detection_counter\"] = mapocam.outlier_detection_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_max_counter_1 = pd.DataFrame(mapocam2_lgr_results).T.prob_max_counter.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 21%|██        | 7/34 [00:00<00:00, 65.12it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 44%|████▍     | 15/34 [00:00<00:00, 70.89it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "100%|██████████| 34/34 [00:00<00:00, 124.74it/s]\n"
     ]
    }
   ],
   "source": [
    "mapocam2_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM2(\n",
    "            action_set, \n",
    "            individual, \n",
    "            clf_lgr_shap_2, \n",
    "            max_changes=float('inf'), \n",
    "            compare=criteria\n",
    "    )\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam2_lgr_results[i] = {}\n",
    "    mapocam2_lgr_results[i]['enum'] = mapocam\n",
    "    mapocam2_lgr_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam2_lgr_results[i]['time'] = mapocam_time\n",
    "    mapocam2_lgr_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')\n",
    "    mapocam2_lgr_results[i][\"prob_max_counter\"] = mapocam.prob_max_counter\n",
    "    mapocam2_lgr_results[i][\"outlier_detection_counter\"] = mapocam.outlier_detection_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_max_counter_2 = pd.DataFrame(mapocam2_lgr_results).T.prob_max_counter.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (4, 4),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (3, 3),\n",
       " (0, 0),\n",
       " (3, 3),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(prob_max_counter_1, prob_max_counter_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4117647058823529, 0.4117647058823529)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_max_counter_1.mean(), prob_max_counter_2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison for single objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_lgr_costs = np.array([lp_lgr_results[i]['cost'] for i in denied_individuals])\n",
    "greedy_lgr_costs = np.array([greedy_lgr_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_lgr_costs = np.array([mapocam_lgr_results[i]['cost'] for i in denied_individuals])\n",
    "\n",
    "lp_lgr_time = np.array([lp_lgr_results[i]['time'] for i in denied_individuals])\n",
    "greedy_lgr_time = np.array([greedy_lgr_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_lgr_time = np.array([mapocam_lgr_results[i]['time'] for i in denied_individuals])\n",
    "\n",
    "best_costs = np.min([lp_lgr_costs, greedy_lgr_costs, mapocam_lgr_costs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_dict = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM': float(np.mean(mapocam_lgr_time)),\n",
    "                'greedy': float(np.mean(greedy_lgr_time)),\n",
    "                'mi-logistic': float(np.mean(lp_lgr_time)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "            {\n",
    "                'MAPOCAM':float(np.mean(mapocam_lgr_costs==best_costs)),\n",
    "                'greedy': float(np.mean(greedy_lgr_costs==best_costs)),\n",
    "                'mi-logistic': float(np.mean(lp_lgr_costs==best_costs)),\n",
    "            },\n",
    "            'Feasible rate':1-float(np.mean(np.isinf(mapocam_lgr_costs))),\n",
    "            'Number of combinations':log_combinations\n",
    "    \n",
    "}\n",
    "save_result(lgr_dict, 'german', 'logistic', 'MPC cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Pareto enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile vs changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM(action_set, individual, clf_lgr_mapocam, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=True, clean_suboptimal=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_results_pc[i] = {}\n",
    "    mapocam_results_pc[i]['enum'] = mapocam\n",
    "    mapocam_results_pc[i]['time'] = mapocam_time\n",
    "    mapocam_results_pc[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = LinearRecourseActionsMulti(action_set, individual, coefficients, intercept,\n",
    "                                    threshold, max_changes=3, enumeration_type='remove_number_actions',\n",
    "                                    compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_results_pc[i] = {}\n",
    "    lp_results_pc[i]['enum'] = lp\n",
    "    lp_results_pc[i]['time'] = lp_time\n",
    "    lp_results_pc[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    bf = BruteForce(action_set, individual, clf_lgr_mapocam, max_changes=3, compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_results_pc[i] = {}\n",
    "    bf_results_pc[i]['enum'] = bf\n",
    "    bf_results_pc[i]['time'] = bf_time\n",
    "    bf_results_pc[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_sols_pc = np.array([bf_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_sols_pc = np.array([mapocam_results_pc[i]['num'] for i in denied_individuals])\n",
    "lp_sols_pc = np.array([lp_results_pc[i]['num'] for i in denied_individuals])\n",
    "best_sols_pc = brute_sols_pc\n",
    "\n",
    "brute_time_pc = np.array([bf_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_time_pc = np.array([mapocam_results_pc[i]['time'] for i in denied_individuals])\n",
    "lp_time_pc = np.array([lp_results_pc[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_dict_pc = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM': float(np.mean(mapocam_time_pc)),\n",
    "                'brute-force': float(np.mean(brute_time_pc)),\n",
    "                'po-mi-logistic': float(np.mean(lp_time_pc)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM':float(np.mean(mapocam_sols_pc==best_sols_pc)),\n",
    "               'brute-force': float(np.mean(brute_sols_pc==best_sols_pc)),\n",
    "               'po-mi-logistic': float(np.mean(lp_sols_pc==best_sols_pc)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(lgr_dict_pc, 'german', 'logistic', 'MPC vs. #changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM(action_set, individual, clf_lgr_mapocam,\n",
    "                      max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_results_feat[i] = {}\n",
    "    mapocam_results_feat[i]['enum'] = mapocam\n",
    "    mapocam_results_feat[i]['time'] = mapocam_time\n",
    "    mapocam_results_feat[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = LinearRecourseActionsMulti(action_set, individual, coefficients, intercept,\n",
    "                                    threshold, max_changes=3, enumeration_type='remove_dominated')\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_results_feat[i] = {}\n",
    "    lp_results_feat[i]['enum'] = lp\n",
    "    lp_results_feat[i]['time'] = lp_time\n",
    "    lp_results_feat[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    bf = BruteForce(action_set, individual, clf_lgr_mapocam, max_changes=3)\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_results_feat[i] = {}\n",
    "    bf_results_feat[i]['enum'] = bf\n",
    "    bf_results_feat[i]['time'] = bf_time\n",
    "    bf_results_feat[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_sols_feat = np.array([bf_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_sols_feat = np.array([mapocam_results_feat[i]['num'] for i in denied_individuals])\n",
    "lp_sols_feat = np.array([lp_results_feat[i]['num'] for i in denied_individuals])\n",
    "best_sols_feat = brute_sols_feat\n",
    "\n",
    "brute_time_feat = np.array([bf_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_time_feat = np.array([mapocam_results_feat[i]['time'] for i in denied_individuals])\n",
    "lp_time_feat = np.array([lp_results_feat[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_dict_feat = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM': float(np.mean(mapocam_time_feat)),\n",
    "                'brute-force': float(np.mean(brute_time_feat)),\n",
    "                'po-mi-logistic': float(np.mean(lp_time_feat)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM':float(np.mean(mapocam_sols_feat==best_sols_feat)),\n",
    "               'brute-force': float(np.mean(brute_sols_feat==best_sols_feat)),\n",
    "               'po-mi-logistic': float(np.mean(lp_sols_feat==best_sols_feat)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(lgr_dict_feat, 'german', 'logistic', 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble\n",
    "from cfmining.mip_algorithms import ForestRecourseActions\n",
    "from cfmining.predictors import TreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rt = ensemble.RandomForestClassifier(n_estimators=5, max_depth=5, max_leaf_nodes=31,\n",
    "                                         class_weight='balanced_subsample')\n",
    "clf_rt.fit(Xtr, ytr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing counterfactual parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionSet stats\n",
      "Number of actionable features: 3\n",
      "Mean number of actions per feature: 9.285714285714286\n",
      "Max number of actions per feature: 27\n",
      "Number of combinations: 1904\n"
     ]
    }
   ],
   "source": [
    "action_set_tree = copy.deepcopy(action_set_base)\n",
    "action_set_tree.embed_forest(clf_rt)\n",
    "for action in action_set_tree:\n",
    "    action.flip_direction = action.step_direction\n",
    "    \n",
    "print('ActionSet stats')\n",
    "print('Number of actionable features:', sum([action.mutable for action in action_set_tree]))\n",
    "print('Mean number of actions per feature:', np.mean([len(action._grid)-1 for action in action_set_tree]))\n",
    "print('Max number of actions per feature:', np.max([len(action._grid)-1 for action in action_set_tree]))\n",
    "rt_combinations = int(np.prod([len(action._grid) for action in action_set_tree if action.actionable]))\n",
    "print('Number of combinations:', rt_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.Series(clf_rt.predict_proba(Xts)[:, 1])\n",
    "denied_individuals = scores.loc[lambda s: s < threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "percCalc = PercentileCalculator(action_set=action_set_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_clf_rf = TreeClassifier(clf_rt, Xtr, ytr, threshold=threshold)\n",
    "mapocam_clf_rf_fast = TreeClassifier(clf_rt, Xtr, ytr, threshold=threshold, use_predict_max=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_shap = GeneralClassifier_Shap(clf_rt, X=Xtr, y=ytr, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LoanDuration', 0.09061631274461034, 0.243646646062386),\n",
       " ('LoanAmount', 0.036798365851921644, 0.07029098510744773),\n",
       " ('Age', 0.03161958626726464, 0.13768185864239407),\n",
       " ('Single', 0.02250859137918783, 0.0648081455533384),\n",
       " ('ForeignWorker', 0.015064389479717867, 0.18179992504239437),\n",
       " ('LoanRateAsPercentOfIncome', 0.01274178859934849, 0.12403375808021526),\n",
       " ('isMale', 0.010102566725003013, 0.0639169046402256)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = list(zip(Xtr.columns, clf_rf_shap.importances, clf_rf_shap.shap_max))\n",
    "imp.sort(key=lambda x: x[1], reverse=True)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 901it [00:13, 25.78it/s]                          \n"
     ]
    }
   ],
   "source": [
    "clf_rf_shap = GeneralClassifier_Shap(clf_rt, outlier_detection=outlier_detection, X=Xtr, y=ytr, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LoanDuration', 0.08396093310336354, 0.2779718140399186),\n",
       " ('Age', 0.057508943987659815, 0.19671331484564517),\n",
       " ('LoanAmount', 0.03662699766295823, 0.13678909653787466),\n",
       " ('Single', 0.021008334734129636, 0.06347488540425911),\n",
       " ('isMale', 0.012080998224669705, 0.08227360496431882),\n",
       " ('LoanRateAsPercentOfIncome', 0.01144972571009471, 0.12564793716935008),\n",
       " ('ForeignWorker', 0.006460803714000895, 5.947448460845439e-05)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = list(zip(Xtr.columns, clf_rf_shap.importances, clf_rf_shap.shap_max))\n",
    "imp.sort(key=lambda x: x[1], reverse=True)\n",
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_tree, individual,\n",
    "                               clf_rt, threshold=threshold,\n",
    "                               max_changes=float('inf'))\n",
    "    lp.build_model()\n",
    "    lp.fit(threads=1)\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_rf_results[i] = {}\n",
    "    lp_rf_results[i]['enum'] = lp\n",
    "    lp_rf_results[i]['indiv'] = individual\n",
    "    lp_rf_results[i]['solution'] = lp.solution#[int(s) if act.variable_type=='int' else float(s) for s, act in zip(pl.solution, action_set)]\n",
    "    lp_rf_results[i]['time'] = lp_time\n",
    "    lp_rf_results[i]['cost'] = criteria.f(lp_rf_results[i]['solution']) if not any(np.isnan(lp_rf_results[i]['solution'])) else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_rf_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    greedy = Greedy(action_set_tree, individual, mapocam_clf_rf_fast, criteria)\n",
    "    greedy.fit()\n",
    "    greedy_time = time.perf_counter()-start\n",
    "    \n",
    "    greedy_rf_results[i] = {}\n",
    "    greedy_rf_results[i]['solution'] = greedy.solution\n",
    "    greedy_rf_results[i]['time'] = greedy_time\n",
    "    greedy_rf_results[i]['cost'] = criteria.f(greedy.solution) if greedy.solution is not None else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 15/38 [00:00<00:00, 144.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 125.31it/s]\n"
     ]
    }
   ],
   "source": [
    "mapocam_rf_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual,\n",
    "                      mapocam_clf_rf, max_changes=float('inf'),\n",
    "                      compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results[i] = {}\n",
    "    mapocam_rf_results[i]['enum'] = mapocam\n",
    "    mapocam_rf_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_rf_results[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual,\n",
    "                      mapocam_clf_rf_fast, max_changes=float('inf'),\n",
    "                      compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_plus[i] = {}\n",
    "    mapocam_rf_results_plus[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_plus[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_rf_results_plus[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_plus[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapocam 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/38 [00:00<?, ?it/s]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  0%|          | 0/38 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'IsolationForest' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m      7\u001b[0m mapocam \u001b[38;5;241m=\u001b[39m MAPOCAM2(\n\u001b[1;32m      8\u001b[0m     action_set, \n\u001b[1;32m      9\u001b[0m     individual, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     compare\u001b[38;5;241m=\u001b[39mcriteria\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmapocam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m mapocam_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\u001b[38;5;241m-\u001b[39mstart\n\u001b[1;32m     18\u001b[0m mapocam2_rf_results[i] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/hiaac/cfmining/cfmining/algorithms.py:798\u001b[0m, in \u001b[0;36mMAPOCAM2.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;66;03m# print([key[0] for key in self.calls])\u001b[39;00m\n\u001b[1;32m    797\u001b[0m         _, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalls\u001b[38;5;241m.\u001b[39mpopitem()\n\u001b[0;32m--> 798\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_suboptimal:\n\u001b[1;32m    801\u001b[0m     solutions \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/hiaac/cfmining/cfmining/algorithms.py:736\u001b[0m, in \u001b[0;36mMAPOCAM2.find_candidates\u001b[0;34m(self, solution, size, changes)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_proba \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps:                \n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# Only save if it is not an outlier\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutlier_detection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutlier_detection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(new_solution[\u001b[38;5;28;01mNone\u001b[39;00m, :]))\n\u001b[1;32m    737\u001b[0m         outlier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutlier_detection\u001b[38;5;241m.\u001b[39mpredict(new_solution[\u001b[38;5;28;01mNone\u001b[39;00m, :]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outlier:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IsolationForest' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "mapocam2_rf_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM2(\n",
    "        action_set, \n",
    "        individual, \n",
    "        clf_rf_shap, \n",
    "        outlier_detection,\n",
    "        max_changes=float('inf'), \n",
    "        compare=criteria\n",
    "    )\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam2_rf_results[i] = {}\n",
    "    mapocam2_rf_results[i]['enum'] = mapocam\n",
    "    mapocam2_rf_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam2_rf_results[i]['time'] = mapocam_time\n",
    "    mapocam2_rf_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')\n",
    "    mapocam2_rf_results[i][\"outlier_detection_counter\"] = mapocam.outlier_detection_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542178fd0>,\n",
       "  'solution': None,\n",
       "  'time': 0.5197362200001407,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 3},\n",
       " 1: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542305180>,\n",
       "  'solution': None,\n",
       "  'time': 0.027307844999995723,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 6: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542304880>,\n",
       "  'solution': None,\n",
       "  'time': 0.11601910100034729,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 4},\n",
       " 7: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54227b4c0>,\n",
       "  'solution': None,\n",
       "  'time': 0.02056248200005939,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 8: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217b4c0>,\n",
       "  'solution': None,\n",
       "  'time': 0.026366496000264306,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 9: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542178040>,\n",
       "  'solution': None,\n",
       "  'time': 0.018908365000243066,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 11: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542305480>,\n",
       "  'solution': None,\n",
       "  'time': 0.027654339000036998,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 19: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542306230>,\n",
       "  'solution': None,\n",
       "  'time': 0.023918493000110175,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 29: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542179240>,\n",
       "  'solution': None,\n",
       "  'time': 0.027208282000174222,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 31: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc5421797e0>,\n",
       "  'solution': None,\n",
       "  'time': 0.025696396000057575,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 33: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217afe0>,\n",
       "  'solution': None,\n",
       "  'time': 0.029969296000217582,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 34: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc5421797b0>,\n",
       "  'solution': None,\n",
       "  'time': 0.026465186000223184,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 35: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217a4a0>,\n",
       "  'solution': None,\n",
       "  'time': 0.02927833500007182,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 38: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217b3d0>,\n",
       "  'solution': array([  0,   1,  21,  60, 425,   1,   1]),\n",
       "  'time': 0.4185800810000728,\n",
       "  'cost': 0.9499675887784597,\n",
       "  'outlier_detection_counter': 6},\n",
       " 40: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217bb80>,\n",
       "  'solution': None,\n",
       "  'time': 0.03218517999994219,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 41: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542178d30>,\n",
       "  'solution': None,\n",
       "  'time': 0.0613932449996355,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 2},\n",
       " 42: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217a3b0>,\n",
       "  'solution': None,\n",
       "  'time': 0.042648189999908936,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 2},\n",
       " 43: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217a2f0>,\n",
       "  'solution': None,\n",
       "  'time': 0.557841264000217,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 5},\n",
       " 49: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc5422d3f40>,\n",
       "  'solution': None,\n",
       "  'time': 0.029252588999952422,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 53: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542179600>,\n",
       "  'solution': None,\n",
       "  'time': 0.0288212359996578,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 67: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542178070>,\n",
       "  'solution': None,\n",
       "  'time': 0.030355878000136727,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 70: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217ba00>,\n",
       "  'solution': None,\n",
       "  'time': 0.026270305000252847,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 71: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217a200>,\n",
       "  'solution': None,\n",
       "  'time': 0.030607904000135022,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 73: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217bbb0>,\n",
       "  'solution': None,\n",
       "  'time': 0.026004520000242337,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 77: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217bfa0>,\n",
       "  'solution': None,\n",
       "  'time': 0.03510128000016266,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 78: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217bf70>,\n",
       "  'solution': None,\n",
       "  'time': 0.023747705000005226,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 80: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542179780>,\n",
       "  'solution': None,\n",
       "  'time': 0.03377089100013109,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 81: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc5421786d0>,\n",
       "  'solution': None,\n",
       "  'time': 0.03196978300002229,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 82: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217af20>,\n",
       "  'solution': None,\n",
       "  'time': 0.6758808459999273,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 5},\n",
       " 83: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc5424123e0>,\n",
       "  'solution': None,\n",
       "  'time': 1.2397981409999375,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 8},\n",
       " 84: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217b2e0>,\n",
       "  'solution': None,\n",
       "  'time': 0.019773574999817356,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 85: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542179d50>,\n",
       "  'solution': None,\n",
       "  'time': 0.03269412000008742,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 87: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217b640>,\n",
       "  'solution': None,\n",
       "  'time': 0.02475238499982879,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 88: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217bd30>,\n",
       "  'solution': None,\n",
       "  'time': 0.01752531700003601,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 90: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217b340>,\n",
       "  'solution': None,\n",
       "  'time': 0.01785883599995941,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 92: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc5421794b0>,\n",
       "  'solution': None,\n",
       "  'time': 0.026706046000072092,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 1},\n",
       " 94: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc54217a3e0>,\n",
       "  'solution': None,\n",
       "  'time': 2.5043891420000364,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 11},\n",
       " 97: {'enum': <cfmining.algorithms.MAPOCAM2 at 0x7fc542306fe0>,\n",
       "  'solution': None,\n",
       "  'time': 0.06373729100005221,\n",
       "  'cost': inf,\n",
       "  'outlier_detection_counter': 2}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapocam2_rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapocam.prob_max_counter, mapocam.outlier_detection_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6279486449911929, 1.5361950600035925)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([v[\"time\"] for v in mapocam_rf_results.values() if v[\"solution\"] is not None]), np.sum([v[\"time\"] for v in mapocam2_rf_results.values() if v[\"solution\"] is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison for single objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_costs = np.array([lp_rf_results[i]['cost'] for i in denied_individuals])\n",
    "greedy_rf_costs = np.array([greedy_rf_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_rf_costs = np.array([mapocam_rf_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_rf_costs_plus = np.array([mapocam_rf_results_plus[i]['cost'] for i in denied_individuals])\n",
    "best_costs_rf = np.min([lp_rf_costs, greedy_rf_costs, mapocam_rf_costs, mapocam_rf_costs_plus], axis=0)\n",
    "\n",
    "lp_rf_time = np.array([lp_rf_results[i]['time'] for i in denied_individuals])\n",
    "greedy_rf_time = np.array([greedy_rf_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time = np.array([mapocam_rf_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_plus = np.array([mapocam_rf_results_plus[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_rf_time_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_rf_time)),\n",
    "                'greedy': float(np.mean(greedy_rf_time)),\n",
    "                'mi-trees': float(np.mean(lp_rf_time)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_rf_costs_plus==best_costs_rf)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_rf_costs==best_costs_rf)),\n",
    "               'greedy': float(np.mean(greedy_rf_costs==best_costs_rf)),\n",
    "               'mi-trees': float(np.mean(lp_rf_costs==best_costs_rf)),\n",
    "           },\n",
    "             'Feasible rate':1-float(np.mean(np.isinf(mapocam_rf_costs_plus))),\n",
    "             'Number of combinations': rt_combinations\n",
    "    \n",
    "}\n",
    "save_result(tree_dict, 'german', 'tree', 'MPC cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Pareto enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile vs changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual,\n",
    "                      mapocam_clf_rf, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_pc[i] = {}\n",
    "    mapocam_rf_results_pc[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_pc[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_pc[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_pc_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual,\n",
    "                      mapocam_clf_rf_fast, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_pc_plus[i] = {}\n",
    "    mapocam_rf_results_pc_plus[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_pc_plus[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_pc_plus[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_tree, individual, clf_rt, threshold=threshold,\n",
    "                               max_changes=3, multi_solution=True,\n",
    "                               cost_type='linear', compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    lp.build_model()\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_rf_results_pc[i] = {}\n",
    "    lp_rf_results_pc[i]['enum'] = lp\n",
    "    lp_rf_results_pc[i]['time'] = lp_time\n",
    "    lp_rf_results_pc[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_rf_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    bf = BruteForce(action_set_tree, individual, mapocam_clf_rf_fast, max_changes=3, compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_rf_results_pc[i] = {}\n",
    "    bf_rf_results_pc[i]['enum'] = bf\n",
    "    bf_rf_results_pc[i]['time'] = bf_time\n",
    "    bf_rf_results_pc[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_sols_pc = np.array([lp_rf_results_pc[i]['num'] for i in denied_individuals])\n",
    "brute_rf_sols_pc = np.array([bf_rf_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_rf_sols_pc = np.array([mapocam_rf_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_rf_sols_pc_plus = np.array([mapocam_rf_results_pc_plus[i]['num'] for i in denied_individuals])\n",
    "best_rf_sols_pc = brute_rf_sols_pc\n",
    "\n",
    "lp_rf_time_pc = np.array([lp_rf_results_pc[i]['time'] for i in denied_individuals])\n",
    "brute_rf_time_pc = np.array([bf_rf_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_pc = np.array([mapocam_rf_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_pc_plus = np.array([mapocam_rf_results_pc_plus[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict_pc = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_rf_time_pc_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_rf_time_pc)),\n",
    "                'brute-force': float(np.mean(brute_rf_time_pc)),\n",
    "                'po-mi-trees': float(np.mean(lp_rf_time_pc)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_rf_sols_pc_plus==best_rf_sols_pc)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_rf_sols_pc==best_rf_sols_pc)),\n",
    "               'brute-force': float(np.mean(brute_rf_sols_pc==best_rf_sols_pc)),\n",
    "               'po-mi-trees': float(np.mean(lp_rf_sols_pc==best_rf_sols_pc)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(tree_dict_pc, 'german', 'tree', 'MPC vs. #changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual, mapocam_clf_rf, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_feat[i] = {}\n",
    "    mapocam_rf_results_feat[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_feat[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_feat[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_feat_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual, mapocam_clf_rf_fast, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_feat_plus[i] = {}\n",
    "    mapocam_rf_results_feat_plus[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_feat_plus[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_feat_plus[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_tree, individual, clf_rt, threshold=threshold,\n",
    "                               max_changes=3, multi_solution=True,\n",
    "                               cost_type='linear')\n",
    "    lp.build_model()\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_rf_results_feat[i] = {}\n",
    "    lp_rf_results_feat[i]['enum'] = lp\n",
    "    lp_rf_results_feat[i]['time'] = lp_time\n",
    "    lp_rf_results_feat[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_rf_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    bf = BruteForce(action_set_tree, individual, mapocam_clf_rf_fast, max_changes=3)\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_rf_results_feat[i] = {}\n",
    "    bf_rf_results_feat[i]['enum'] = bf\n",
    "    bf_rf_results_feat[i]['time'] = bf_time\n",
    "    bf_rf_results_feat[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_rf_sols_feat = np.array([bf_rf_results_feat[i]['num'] for i in denied_individuals])\n",
    "lp_rf_sols_feat = np.array([lp_rf_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_rf_sols_feat = np.array([mapocam_rf_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_rf_sols_feat_plus = np.array([mapocam_rf_results_feat_plus[i]['num'] for i in denied_individuals])\n",
    "best_rf_sols_feat = brute_rf_sols_feat\n",
    "\n",
    "brute_rf_time_feat = np.array([bf_rf_results_feat[i]['time'] for i in denied_individuals])\n",
    "lp_rf_time_feat = np.array([lp_rf_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_feat = np.array([mapocam_rf_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_feat_plus = np.array([mapocam_rf_results_feat_plus[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict_feat = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_rf_time_feat_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_rf_time_feat)),\n",
    "                'brute-force': float(np.mean(brute_rf_time_feat)),\n",
    "                'po-mi-trees': float(np.mean(lp_rf_time_feat)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_rf_sols_feat_plus==best_rf_sols_feat)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_rf_sols_feat==best_rf_sols_feat)),\n",
    "               'brute-force': float(np.mean(brute_rf_sols_feat==best_rf_sols_feat)),\n",
    "               'po-mi-trees': float(np.mean(lp_rf_sols_feat==best_rf_sols_feat)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(tree_dict_feat, 'german', 'tree', 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monotone trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble\n",
    "import lightgbm\n",
    "from cfmining.predictors import MonotoneTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotone_constraints = [action.step_direction for action in action_set_base]\n",
    "clf_mt = lightgbm.LGBMClassifier(n_estimators=10, max_depth=10, num_leaves=63,\n",
    "                                 monotone_constraints=monotone_constraints, class_weight='balanced')\n",
    "clf_mt.fit(Xtr, ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing counterfactual parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set_mtree = copy.deepcopy(action_set_base)\n",
    "action_set_mtree.embed_forest(clf_mt)\n",
    "for action in action_set_mtree:\n",
    "    action.flip_direction = action.step_direction\n",
    "\n",
    "print('ActionSet stats')\n",
    "print('Number of actionable features:', sum([action.mutable for action in action_set_mtree]))\n",
    "print('Mean number of actions per feature:', np.mean([len(action._grid)-1 for action in action_set_mtree]))\n",
    "print('Max number of actions per feature:', np.max([len(action._grid)-1 for action in action_set_mtree]))\n",
    "mt_combinations = int(np.prod([len(action._grid) for action in action_set_mtree if action.actionable]))\n",
    "print('Number of combinations:', mt_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.Series(clf_mt.predict_proba(Xts)[:, 1])\n",
    "denied_individuals = scores.loc[lambda s: s < threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percCalc = PercentileCalculator(action_set=action_set_mtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_clf_mt = TreeClassifier(clf_mt, Xtr, ytr, clf_type='lightgbm', threshold=threshold)\n",
    "mapocam_clf_mt_fast = TreeClassifier(clf_mt, Xtr, ytr, clf_type='lightgbm', threshold=threshold, use_predict_max=True)\n",
    "mapocam_clf_mt_mon = MonotoneTree(clf_mt, Xtr, ytr, clf_type='lightgbm', threshold=threshold, use_predict_max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_mt_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_mtree, individual, clf_mt, clf_type='lightgbm', threshold=threshold, max_changes=float('inf'))\n",
    "    lp.build_model()\n",
    "    lp.fit(threads=1)\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_mt_results[i] = {}\n",
    "    lp_mt_results[i]['enum'] = lp\n",
    "    lp_mt_results[i]['indiv'] = individual\n",
    "    lp_mt_results[i]['solution'] = lp.solution#[int(s) if act.variable_type=='int' else float(s) for s, act in zip(pl.solution, action_set)]\n",
    "    lp_mt_results[i]['time'] = lp_time\n",
    "    lp_mt_results[i]['cost'] = criteria.f(lp_mt_results[i]['solution']) if not any(np.isnan(lp_mt_results[i]['solution'])) else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_mt_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    greedy = Greedy(action_set_mtree, individual, mapocam_clf_mt_fast, criteria)\n",
    "    greedy.fit()\n",
    "    greedy_time = time.perf_counter()-start\n",
    "    \n",
    "    greedy_mt_results[i] = {}\n",
    "    greedy_mt_results[i]['solution'] = greedy.solution\n",
    "    greedy_mt_results[i]['time'] = greedy_time\n",
    "    greedy_mt_results[i]['cost'] = criteria.f(greedy.solution) if greedy.solution is not None else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, \n",
    "                      mapocam_clf_mt, max_changes=float('inf'), \n",
    "                      compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results[i] = {}\n",
    "    mapocam_mt_results[i]['enum'] = mapocam\n",
    "    mapocam_mt_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_mt_results[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, \n",
    "                      mapocam_clf_mt_fast, max_changes=float('inf'),\n",
    "                      compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_plus[i] = {}\n",
    "    mapocam_mt_results_plus[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_plus[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_mt_results_plus[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_plus[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_mon = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_mon.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, mapocam_clf_mt_mon, max_changes=float('inf'), compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_mon[i] = {}\n",
    "    mapocam_mt_results_mon[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_mon[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_mt_results_mon[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_mon[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_mt_costs = np.array([lp_mt_results[i]['cost'] for i in denied_individuals])\n",
    "greedy_mt_costs = np.array([greedy_mt_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_mt_costs = np.array([mapocam_mt_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_mt_costs_plus = np.array([mapocam_mt_results_plus[i]['cost'] for i in denied_individuals])\n",
    "mapocam_mt_costs_mon = np.array([mapocam_mt_results_mon[i]['cost'] for i in denied_individuals])\n",
    "best_costs_mt_rf = np.min([lp_mt_costs, greedy_mt_costs, mapocam_mt_costs, mapocam_mt_costs_plus, mapocam_mt_costs_mon], axis=0)\n",
    "\n",
    "lp_mt_time = np.array([lp_mt_results[i]['time'] for i in denied_individuals])\n",
    "greedy_mt_time = np.array([greedy_mt_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time = np.array([mapocam_mt_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_plus = np.array([mapocam_mt_results_plus[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_mon = np.array([mapocam_mt_results_mon[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-M': float(np.mean(mapocam_mt_time_mon)),\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_mt_time_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_mt_time)),\n",
    "                'greedy': float(np.mean(greedy_mt_time)),\n",
    "                'mi-trees': float(np.mean(lp_mt_time)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-M':float(np.mean(mapocam_mt_costs_mon==best_costs_mt_rf)),\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_mt_costs_plus==best_costs_mt_rf)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_mt_costs==best_costs_mt_rf)),\n",
    "               'greedy': float(np.mean(greedy_mt_costs==best_costs_mt_rf)),\n",
    "               'mi-trees': float(np.mean(lp_mt_costs==best_costs_mt_rf)),\n",
    "           },\n",
    "             'Feasible rate':1-float(np.mean(np.isinf(mapocam_mt_costs_mon))),\n",
    "             'Number of combinations': mt_combinations\n",
    "    \n",
    "}\n",
    "save_result(tree_dict, 'german', 'monotone-tree', 'MPC cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Pareto enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile vs changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, \n",
    "                      mapocam_clf_mt, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_pc[i] = {}\n",
    "    mapocam_mt_results_pc[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_pc[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_pc[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_pc_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual,\n",
    "                      mapocam_clf_mt_fast, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_pc_plus[i] = {}\n",
    "    mapocam_mt_results_pc_plus[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_pc_plus[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_pc_plus[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_pc_mon = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_mon.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual,\n",
    "                      mapocam_clf_mt_mon, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_pc_mon[i] = {}\n",
    "    mapocam_mt_results_pc_mon[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_pc_mon[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_pc_mon[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_mt_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_mtree, individual, clf_mt, clf_type='lightgbm', threshold=threshold,\n",
    "                               max_changes=3, multi_solution=True,\n",
    "                               cost_type='linear', compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    lp.build_model()\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_mt_results_pc[i] = {}\n",
    "    lp_mt_results_pc[i]['enum'] = lp\n",
    "    lp_mt_results_pc[i]['time'] = lp_time\n",
    "    lp_mt_results_pc[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_mt_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    bf = BruteForce(action_set_mtree, individual, mapocam_clf_mt_fast, max_changes=3, compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_mt_results_pc[i] = {}\n",
    "    bf_mt_results_pc[i]['enum'] = bf\n",
    "    bf_mt_results_pc[i]['time'] = bf_time\n",
    "    bf_mt_results_pc[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_mt_sols_pc = np.array([bf_mt_results_pc[i]['num'] for i in denied_individuals])\n",
    "lp_mt_sols_pc = np.array([lp_mt_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_pc = np.array([mapocam_mt_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_pc_plus = np.array([mapocam_mt_results_pc_plus[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_pc_mon = np.array([mapocam_mt_results_pc_mon[i]['num'] for i in denied_individuals])\n",
    "best_mt_sols_pc = brute_mt_sols_pc\n",
    "\n",
    "brute_mt_time_pc = np.array([bf_mt_results_pc[i]['time'] for i in denied_individuals])\n",
    "lp_mt_time_pc = np.array([lp_mt_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_pc = np.array([mapocam_mt_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_pc_plus = np.array([mapocam_mt_results_pc_plus[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_pc_mon = np.array([mapocam_mt_results_pc_mon[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_tree_dict_pc = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-M': float(np.mean(mapocam_mt_time_pc_mon)),\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_mt_time_pc_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_mt_time_pc)),\n",
    "                'brute-force': float(np.mean(brute_mt_time_pc)),\n",
    "                'po-mi-trees': float(np.mean(lp_mt_time_pc)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-M':float(np.mean(mapocam_mt_sols_pc_plus==mapocam_mt_sols_pc_mon)),\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_mt_sols_pc_plus==best_mt_sols_pc)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_mt_sols_pc==best_mt_sols_pc)),\n",
    "               'brute-force': float(np.mean(brute_mt_sols_pc==best_mt_sols_pc)),\n",
    "               'po-mi-trees': float(np.mean(lp_mt_sols_pc==best_mt_sols_pc)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(mon_tree_dict_pc, 'german', 'monotone-tree', 'MPC vs. #changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, mapocam_clf_mt, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_feat[i] = {}\n",
    "    mapocam_mt_results_feat[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_feat[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_feat[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_feat_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, mapocam_clf_mt_fast, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_feat_plus[i] = {}\n",
    "    mapocam_mt_results_feat_plus[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_feat_plus[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_feat_plus[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_feat_mon = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_mon.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, mapocam_clf_mt_mon, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_feat_mon[i] = {}\n",
    "    mapocam_mt_results_feat_mon[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_feat_mon[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_feat_mon[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_mt_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_mtree, individual, clf_mt, clf_type='lightgbm', threshold=threshold,\n",
    "                               max_changes=3, multi_solution=True,\n",
    "                               cost_type='linear')\n",
    "    lp.build_model()\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_mt_results_feat[i] = {}\n",
    "    lp_mt_results_feat[i]['enum'] = lp\n",
    "    lp_mt_results_feat[i]['time'] = lp_time\n",
    "    lp_mt_results_feat[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_mt_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    bf = BruteForce(action_set_mtree, individual, mapocam_clf_mt_fast, max_changes=3)\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_mt_results_feat[i] = {}\n",
    "    bf_mt_results_feat[i]['enum'] = bf\n",
    "    bf_mt_results_feat[i]['time'] = bf_time\n",
    "    bf_mt_results_feat[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_mt_sols_feat = np.array([bf_mt_results_feat[i]['num'] for i in denied_individuals])\n",
    "lp_mt_sols_feat = np.array([lp_mt_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_feat = np.array([mapocam_mt_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_feat_plus = np.array([mapocam_mt_results_feat_plus[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_feat_mon = np.array([mapocam_mt_results_feat_mon[i]['num'] for i in denied_individuals])\n",
    "best_mt_sols_feat = brute_mt_sols_feat\n",
    "\n",
    "brute_mt_time_feat = np.array([bf_mt_results_feat[i]['time'] for i in denied_individuals])\n",
    "lp_mt_time_feat = np.array([lp_mt_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_feat = np.array([mapocam_mt_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_feat_plus = np.array([mapocam_mt_results_feat_plus[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_feat_mon = np.array([mapocam_mt_results_feat_mon[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feasible rate:', np.mean(best_mt_sols_feat!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_tree_dict_feat = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-M': float(np.mean(mapocam_mt_time_feat_mon)),\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_mt_time_feat_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_mt_time_feat)),\n",
    "                'brute-force': float(np.mean(brute_mt_time_feat)),\n",
    "                'po-mi-trees': float(np.mean(lp_mt_time_feat)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-M':float(np.mean(mapocam_mt_sols_feat_mon==best_mt_sols_feat)),\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_mt_sols_feat_plus==best_mt_sols_feat)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_mt_sols_feat==best_mt_sols_feat)),\n",
    "               'brute-force': float(np.mean(brute_mt_sols_feat==best_mt_sols_feat)),\n",
    "               'po-mi-trees': float(np.mean(lp_mt_sols_feat==best_mt_sols_feat)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(mon_tree_dict_feat, 'german', 'monotone-tree', 'feature')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
