{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "from sklearn import preprocessing, pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from cfmining.mip_algorithms import LinearRecourseActions, LinearRecourseActionsMulti\n",
    "from cfmining.algorithms import MAPOCAM, BruteForce, Greedy, MAPOCAM2\n",
    "from cfmining.criteria import PercentileCalculator, PercentileCriterion, PercentileChangesCriterion, NonDomCriterion\n",
    "from cfmining.predictors import MonotoneClassifier, GeneralClassifier, TreeClassifier, LinearClassifier, LinearRule, GeneralClassifier_Shap\n",
    "from cfmining.action_set import ActionSet\n",
    "\n",
    "from results import save_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "data_name = 'german'\n",
    "data_file = os.path.join(data_dir, '%s_processed.csv' % data_name)\n",
    "## load and process data\n",
    "german_df = pd.read_csv(data_file).reset_index(drop=True)\n",
    "german_df = (german_df\n",
    "             .assign(isMale=lambda df: (df['Gender']=='Male').astype(int))\n",
    "             .drop(['PurposeOfLoan', 'Gender', 'OtherLoansAtStore'], axis=1)\n",
    "            )\n",
    "\n",
    "y = german_df['GoodCustomer']\n",
    "# tranform y to [0, 1]\n",
    "y = (y == 1).astype(int)\n",
    "X = german_df.drop('GoodCustomer', axis=1)\n",
    "X = X[['ForeignWorker', 'Single', 'Age', 'LoanDuration', 'LoanAmount', 'LoanRateAsPercentOfIncome', 'isMale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xts, ytr, yts = train_test_split(X, y, test_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detection = IsolationForest(contamination=0.1)\n",
    "outlier_detection.fit(Xtr.values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting ActionSet base parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set_base = ActionSet(X = X)\n",
    "for feat in action_set_base:\n",
    "    if feat.name in ['Age', 'JobClassIsSkilled', 'OwnsHouse', 'isMale', 'JobClassIsSkilled']:\n",
    "        feat.mutable = False\n",
    "        feat.step_direction = 1\n",
    "    if feat.name in ['Single', 'ForeignWorker', 'RentsHouse']:\n",
    "        feat.mutable = False\n",
    "        feat.step_direction = -1\n",
    "    if feat.name in ['LoanDuration', 'LoanAmount', 'LoanRateAsPercentOfIncome', 'NumberOfOtherLoansAtBank', 'MissedPayments',\n",
    "                     'CriticalAccountOrLoansElsewhere', 'OtherLoansAtBank', 'Unemployed', 'YearsAtCurrentJob_lt_1']:\n",
    "        feat.mutable = True\n",
    "        feat.step_direction = -1\n",
    "    if feat.name in ['YearsAtCurrentHome', 'NumberOfLiableIndividuals', 'HasTelephone', 'CheckingAccountBalance_geq_0',\n",
    "                     'CheckingAccountBalance_geq_200', 'SavingsAccountBalance_geq_100', 'SavingsAccountBalance_geq_500',\n",
    "                     'NoCurrentLoan', 'HasCoapplicant', 'HasGuarantor', 'YearsAtCurrentJob_geq_4']:\n",
    "        feat.mutable = True\n",
    "        feat.step_direction = 1\n",
    "    \n",
    "    feat.flip_direction = 1\n",
    "    feat.update_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand = preprocessing.StandardScaler()\n",
    "clf_base = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "clf = pipeline.Pipeline([('std', stand), ('clf', clf_base)])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "  clf, param_grid={'clf__C': np.logspace(-4, 3)},\n",
    "  cv=5,\n",
    "  scoring='roc_auc',\n",
    "  verbose=0\n",
    ")\n",
    "\n",
    "grid.fit(Xtr, ytr)\n",
    "clf_lgr = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.5\n",
    "scores = pd.Series(clf_lgr.predict_proba(Xts)[:, 1])\n",
    "denied_individuals = scores.loc[lambda s: s < threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgr_mapocam = MonotoneClassifier(clf_lgr, X=Xtr, y=ytr, threshold=threshold)\n",
    "coefficients = clf_lgr['clf'].coef_[0]/clf_lgr['std'].scale_\n",
    "intercept = clf_lgr['clf'].intercept_[0]-coefficients@clf_lgr['std'].mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 901it [01:28,  9.80it/s]                         \n"
     ]
    }
   ],
   "source": [
    "clf_lgr_shap = GeneralClassifier_Shap(clf_lgr, X=Xtr, y=ytr, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LoanDuration', 0.04484870130721758, 0.08340935229296217),\n",
       " ('LoanAmount', 0.030163973351294584, 0.04583432136365088),\n",
       " ('LoanRateAsPercentOfIncome', 0.030085474401012984, 0.06782382308648012),\n",
       " ('Age', 0.02964235821026434, 0.12828806922361097),\n",
       " ('Single', 0.028745031809877856, 0.029369125511563156),\n",
       " ('isMale', 0.015604658144219711, 0.010974517425070171),\n",
       " ('ForeignWorker', 0.006664880976964589, 0.14399461782002923)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = list(zip(Xtr.columns, clf_lgr_shap.importances, clf_lgr_shap.shap_max))\n",
    "imp.sort(key=lambda x: x[1], reverse=True)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 901it [00:46, 14.63it/s]                         \n"
     ]
    }
   ],
   "source": [
    "clf_lgr_shap = GeneralClassifier_Shap(clf_lgr, outlier_detection=outlier_detection, X=Xtr, y=ytr, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LoanDuration', 0.04484870130721758, 0.08340935229296217),\n",
       " ('LoanAmount', 0.030163973351294584, 0.04583432136365088),\n",
       " ('LoanRateAsPercentOfIncome', 0.030085474401012984, 0.06782382308648012),\n",
       " ('Age', 0.02964235821026434, 0.12828806922361097),\n",
       " ('Single', 0.028745031809877856, 0.029369125511563156),\n",
       " ('isMale', 0.015604658144219711, 0.010974517425070171),\n",
       " ('ForeignWorker', 0.006664880976964589, -0.0012386953924630462)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = list(zip(Xtr.columns, clf_lgr_shap.importances, clf_lgr_shap.shap_max))\n",
    "imp.sort(key=lambda x: x[1], reverse=True)\n",
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing counterfactual parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionSet stats\n",
      "Number of actionable features: 0\n",
      "Mean number of actions per feature: nan\n",
      "Max number of actions per feature: nan\n",
      "Number of combinations: 172480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean of empty slice\n",
      "All-NaN axis encountered\n"
     ]
    }
   ],
   "source": [
    "action_set = copy.deepcopy(action_set_base)\n",
    "action_set['Age'].mutable = False\n",
    "action_set['Age'].update_grid()\n",
    "\n",
    "action_set['LoanDuration'].step_type =\"absolute\"\n",
    "action_set['LoanDuration'].step_size = 6\n",
    "action_set['LoanDuration'].update_grid()\n",
    "\n",
    "action_set['LoanAmount'].step_size = 0.1\n",
    "action_set['LoanAmount'].update_grid()\n",
    "\n",
    "print('ActionSet stats')\n",
    "print('Number of actionable features:', sum([action.actionable for action in action_set]))\n",
    "print('Mean number of actions per feature:', np.nanmean([len(action._grid) if action.actionable else np.nan for action in action_set]))\n",
    "print('Max number of actions per feature:', np.nanmax([len(action._grid) if action.actionable else np.nan for action in action_set]))\n",
    "log_combinations = int(np.prod([len(action._grid) for action in action_set if action_set.actionable]))\n",
    "print('Number of combinations:', log_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "percCalc = PercentileCalculator(action_set=action_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = LinearRecourseActions(action_set, individual, coefficients, intercept, threshold)\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_lgr_results[i] = {}\n",
    "    lp_lgr_results[i]['enum'] = lp\n",
    "    lp_lgr_results[i]['indiv'] = individual\n",
    "    lp_lgr_results[i]['solution'] = np.array([int(s) if act.variable_type=='int' else float(s) for s, act in zip(lp.solution, action_set)])\n",
    "    lp_lgr_results[i]['stats'] = lp.stats\n",
    "    lp_lgr_results[i]['recourse'] = lp.recourse\n",
    "    lp_lgr_results[i]['time'] = lp_time\n",
    "    lp_lgr_results[i]['cost'] = criteria.f(lp_lgr_results[i]['solution']) if not any(np.isnan(lp_lgr_results[i]['solution'])) else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    greedy = Greedy(action_set, individual, clf_lgr_mapocam, criteria)\n",
    "    greedy.fit()\n",
    "    greedy_time = time.perf_counter()-start\n",
    "    \n",
    "    greedy_lgr_results[i] = {}\n",
    "    greedy_lgr_results[i]['solution'] = greedy.solution\n",
    "    greedy_lgr_results[i]['time'] = greedy_time\n",
    "    greedy_lgr_results[i]['cost'] = criteria.f(greedy.solution) if greedy.solution is not None else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  2%|▏         | 1/47 [00:00<00:17,  2.66it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 13%|█▎        | 6/47 [00:00<00:02, 15.65it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 28%|██▊       | 13/47 [00:00<00:01, 29.82it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 45%|████▍     | 21/47 [00:00<00:00, 42.93it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 62%|██████▏   | 29/47 [00:00<00:00, 51.70it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 77%|███████▋  | 36/47 [00:00<00:00, 53.38it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 91%|█████████▏| 43/47 [00:01<00:00, 50.95it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "100%|██████████| 47/47 [00:01<00:00, 39.83it/s]\n"
     ]
    }
   ],
   "source": [
    "mapocam_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM(action_set, individual, clf_lgr_mapocam,\n",
    "                      max_changes=float('inf'), compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_lgr_results[i] = {}\n",
    "    mapocam_lgr_results[i]['enum'] = mapocam\n",
    "    mapocam_lgr_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_lgr_results[i]['time'] = mapocam_time\n",
    "    mapocam_lgr_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPOCAM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.84909722]\n",
      "max prob: [0.82077022]\n",
      "max prob: [0.79256889]\n",
      "max prob: [0.84727476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.82707009]\n",
      "max prob: [0.80676361]\n",
      "max prob: [0.80185625]\n",
      "max prob: [0.81886206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.79861712]\n",
      "max prob: [0.77836213]\n",
      "max prob: [0.77348088]\n",
      "max prob: [0.79029328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  2%|▏         | 1/45 [00:01<00:55,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.77013738]\n",
      "max prob: [0.75006184]\n",
      "max prob: [0.74523719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.84949589]\n",
      "max prob: [0.82115929]\n",
      "max prob: [0.84699512]\n",
      "max prob: [0.84236055]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 11%|█         | 5/45 [00:01<00:11,  3.42it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.81856335]\n",
      "max prob: [0.81391866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.84951949]\n",
      "max prob: [0.82113495]\n",
      "max prob: [0.79282363]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 24%|██▍       | 11/45 [00:02<00:05,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.76476362]\n",
      "max prob: [0.73712676]\n",
      "max prob: [0.71007454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.84927938]\n",
      "max prob: [0.82094422]\n",
      "max prob: [0.84699512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.82676684]\n",
      "max prob: [0.82592662]\n",
      "max prob: [0.81856335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 33%|███▎      | 15/45 [00:03<00:05,  5.83it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.7983262]\n",
      "max prob: [0.79748759]\n",
      "max prob: [0.84715604]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.81948309]\n",
      "max prob: [0.79207086]\n",
      "max prob: [0.76507586]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.73864539]\n",
      "max prob: [0.71291463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.68800425]\n",
      "max prob: [0.66401861]\n",
      "max prob: [0.6410446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 40%|████      | 18/45 [00:04<00:06,  4.44it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.61915104]\n",
      "max prob: [0.84956231]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.82117872]\n",
      "max prob: [0.79284686]\n",
      "max prob: [0.77875633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.81912836]\n",
      "max prob: [0.79888438]\n",
      "max prob: [0.78702413]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.79055662]\n",
      "max prob: [0.77037072]\n",
      "max prob: [0.75858685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 51%|█████     | 23/45 [00:05<00:05,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.7762571]\n",
      "max prob: [0.75614855]\n",
      "max prob: [0.74443073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.84900342]\n",
      "max prob: [0.82069475]\n",
      "max prob: [0.79252018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.76465438]\n",
      "max prob: [0.84709324]\n",
      "max prob: [0.82687183]\n",
      "max prob: [0.80656045]\n",
      "max prob: [0.8057181]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.81866647]\n",
      "max prob: [0.79842575]\n",
      "max prob: [0.7781865]\n",
      "max prob: [0.7773491]\n",
      "max prob: [0.79010645]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.7699752]\n",
      "max prob: [0.74993514]\n",
      "max prob: [0.74910789]\n",
      "max prob: [0.76159753]\n",
      "max prob: [0.74170164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 60%|██████    | 27/45 [00:06<00:04,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.72198277]\n",
      "max prob: [0.72117062]\n",
      "max prob: [0.85012278]\n",
      "max prob: [0.82173302]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 64%|██████▍   | 29/45 [00:06<00:03,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.79330612]\n",
      "max prob: [0.7838536]\n",
      "max prob: [0.84971525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.82133118]\n",
      "max prob: [0.79296172]\n",
      "max prob: [0.81912836]\n",
      "max prob: [0.79888438]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.7986487]\n",
      "max prob: [0.79055662]\n",
      "max prob: [0.77037072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 71%|███████   | 32/45 [00:07<00:03,  4.24it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.77013625]\n",
      "max prob: [0.84978448]\n",
      "max prob: [0.82141879]\n",
      "max prob: [0.81904324]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 73%|███████▎  | 33/45 [00:07<00:02,  4.25it/s]X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.81131089]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 84%|████████▍ | 38/45 [00:08<00:01,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.84959271]\n",
      "max prob: [0.8212156]\n",
      "max prob: [0.79288582]\n",
      "max prob: [0.76478196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.84905329]\n",
      "max prob: [0.82119128]\n",
      "max prob: [0.79330558]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      " 91%|█████████ | 41/45 [00:08<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [0.76556412]\n",
      "max prob: [0.73813144]\n",
      "max prob: [0.71116503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "100%|██████████| 45/45 [00:08<00:00,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "mapocam2_lgr_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM2(action_set, individual, clf_lgr_shap,\n",
    "                      max_changes=float('inf'), compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam2_lgr_results[i] = {}\n",
    "    mapocam2_lgr_results[i]['enum'] = mapocam\n",
    "    mapocam2_lgr_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam2_lgr_results[i]['time'] = mapocam_time\n",
    "    mapocam2_lgr_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison for single objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_lgr_costs = np.array([lp_lgr_results[i]['cost'] for i in denied_individuals])\n",
    "greedy_lgr_costs = np.array([greedy_lgr_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_lgr_costs = np.array([mapocam_lgr_results[i]['cost'] for i in denied_individuals])\n",
    "\n",
    "lp_lgr_time = np.array([lp_lgr_results[i]['time'] for i in denied_individuals])\n",
    "greedy_lgr_time = np.array([greedy_lgr_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_lgr_time = np.array([mapocam_lgr_results[i]['time'] for i in denied_individuals])\n",
    "\n",
    "best_costs = np.min([lp_lgr_costs, greedy_lgr_costs, mapocam_lgr_costs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_dict = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM': float(np.mean(mapocam_lgr_time)),\n",
    "                'greedy': float(np.mean(greedy_lgr_time)),\n",
    "                'mi-logistic': float(np.mean(lp_lgr_time)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "            {\n",
    "                'MAPOCAM':float(np.mean(mapocam_lgr_costs==best_costs)),\n",
    "                'greedy': float(np.mean(greedy_lgr_costs==best_costs)),\n",
    "                'mi-logistic': float(np.mean(lp_lgr_costs==best_costs)),\n",
    "            },\n",
    "            'Feasible rate':1-float(np.mean(np.isinf(mapocam_lgr_costs))),\n",
    "            'Number of combinations':log_combinations\n",
    "    \n",
    "}\n",
    "save_result(lgr_dict, 'german', 'logistic', 'MPC cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Pareto enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile vs changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM(action_set, individual, clf_lgr_mapocam, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=True, clean_suboptimal=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_results_pc[i] = {}\n",
    "    mapocam_results_pc[i]['enum'] = mapocam\n",
    "    mapocam_results_pc[i]['time'] = mapocam_time\n",
    "    mapocam_results_pc[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = LinearRecourseActionsMulti(action_set, individual, coefficients, intercept,\n",
    "                                    threshold, max_changes=3, enumeration_type='remove_number_actions',\n",
    "                                    compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_results_pc[i] = {}\n",
    "    lp_results_pc[i]['enum'] = lp\n",
    "    lp_results_pc[i]['time'] = lp_time\n",
    "    lp_results_pc[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    bf = BruteForce(action_set, individual, clf_lgr_mapocam, max_changes=3, compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_results_pc[i] = {}\n",
    "    bf_results_pc[i]['enum'] = bf\n",
    "    bf_results_pc[i]['time'] = bf_time\n",
    "    bf_results_pc[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_sols_pc = np.array([bf_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_sols_pc = np.array([mapocam_results_pc[i]['num'] for i in denied_individuals])\n",
    "lp_sols_pc = np.array([lp_results_pc[i]['num'] for i in denied_individuals])\n",
    "best_sols_pc = brute_sols_pc\n",
    "\n",
    "brute_time_pc = np.array([bf_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_time_pc = np.array([mapocam_results_pc[i]['time'] for i in denied_individuals])\n",
    "lp_time_pc = np.array([lp_results_pc[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_dict_pc = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM': float(np.mean(mapocam_time_pc)),\n",
    "                'brute-force': float(np.mean(brute_time_pc)),\n",
    "                'po-mi-logistic': float(np.mean(lp_time_pc)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM':float(np.mean(mapocam_sols_pc==best_sols_pc)),\n",
    "               'brute-force': float(np.mean(brute_sols_pc==best_sols_pc)),\n",
    "               'po-mi-logistic': float(np.mean(lp_sols_pc==best_sols_pc)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(lgr_dict_pc, 'german', 'logistic', 'MPC vs. #changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM(action_set, individual, clf_lgr_mapocam,\n",
    "                      max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_results_feat[i] = {}\n",
    "    mapocam_results_feat[i]['enum'] = mapocam\n",
    "    mapocam_results_feat[i]['time'] = mapocam_time\n",
    "    mapocam_results_feat[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = LinearRecourseActionsMulti(action_set, individual, coefficients, intercept,\n",
    "                                    threshold, max_changes=3, enumeration_type='remove_dominated')\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_results_feat[i] = {}\n",
    "    lp_results_feat[i]['enum'] = lp\n",
    "    lp_results_feat[i]['time'] = lp_time\n",
    "    lp_results_feat[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    bf = BruteForce(action_set, individual, clf_lgr_mapocam, max_changes=3)\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_results_feat[i] = {}\n",
    "    bf_results_feat[i]['enum'] = bf\n",
    "    bf_results_feat[i]['time'] = bf_time\n",
    "    bf_results_feat[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_sols_feat = np.array([bf_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_sols_feat = np.array([mapocam_results_feat[i]['num'] for i in denied_individuals])\n",
    "lp_sols_feat = np.array([lp_results_feat[i]['num'] for i in denied_individuals])\n",
    "best_sols_feat = brute_sols_feat\n",
    "\n",
    "brute_time_feat = np.array([bf_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_time_feat = np.array([mapocam_results_feat[i]['time'] for i in denied_individuals])\n",
    "lp_time_feat = np.array([lp_results_feat[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_dict_feat = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM': float(np.mean(mapocam_time_feat)),\n",
    "                'brute-force': float(np.mean(brute_time_feat)),\n",
    "                'po-mi-logistic': float(np.mean(lp_time_feat)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM':float(np.mean(mapocam_sols_feat==best_sols_feat)),\n",
    "               'brute-force': float(np.mean(brute_sols_feat==best_sols_feat)),\n",
    "               'po-mi-logistic': float(np.mean(lp_sols_feat==best_sols_feat)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(lgr_dict_feat, 'german', 'logistic', 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble\n",
    "from cfmining.mip_algorithms import ForestRecourseActions\n",
    "from cfmining.predictors import TreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rt = ensemble.RandomForestClassifier(n_estimators=5, max_depth=5, max_leaf_nodes=31,\n",
    "                                         class_weight='balanced_subsample')\n",
    "clf_rt.fit(Xtr, ytr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing counterfactual parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionSet stats\n",
      "Number of actionable features: 3\n",
      "Mean number of actions per feature: 11.142857142857142\n",
      "Max number of actions per feature: 33\n",
      "Number of combinations: 2584\n"
     ]
    }
   ],
   "source": [
    "action_set_tree = copy.deepcopy(action_set_base)\n",
    "action_set_tree.embed_forest(clf_rt)\n",
    "for action in action_set_tree:\n",
    "    action.flip_direction = action.step_direction\n",
    "    \n",
    "print('ActionSet stats')\n",
    "print('Number of actionable features:', sum([action.mutable for action in action_set_tree]))\n",
    "print('Mean number of actions per feature:', np.mean([len(action._grid)-1 for action in action_set_tree]))\n",
    "print('Max number of actions per feature:', np.max([len(action._grid)-1 for action in action_set_tree]))\n",
    "rt_combinations = int(np.prod([len(action._grid) for action in action_set_tree if action.actionable]))\n",
    "print('Number of combinations:', rt_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.Series(clf_rt.predict_proba(Xts)[:, 1])\n",
    "denied_individuals = scores.loc[lambda s: s < threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "percCalc = PercentileCalculator(action_set=action_set_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_clf_rf = TreeClassifier(clf_rt, Xtr, ytr, threshold=threshold)\n",
    "mapocam_clf_rf_fast = TreeClassifier(clf_rt, Xtr, ytr, threshold=threshold, use_predict_max=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 901it [00:40, 14.98it/s]                         \n"
     ]
    }
   ],
   "source": [
    "clf_rf_shap = GeneralClassifier_Shap(clf_rt, X=Xtr, y=ytr, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LoanDuration', 0.08396093310336354, 0.2779718140399186),\n",
       " ('Age', 0.057508943987659815, 0.19671331484564517),\n",
       " ('LoanAmount', 0.03662699766295823, 0.1395516791573939),\n",
       " ('Single', 0.021008334734129636, 0.095156324096787),\n",
       " ('isMale', 0.012080998224669705, 0.08227360496431882),\n",
       " ('LoanRateAsPercentOfIncome', 0.01144972571009471, 0.12564793716935008),\n",
       " ('ForeignWorker', 0.006460803714000895, 0.2548199096230261)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = list(zip(Xtr.columns, clf_rf_shap.importances, clf_rf_shap.shap_max))\n",
    "imp.sort(key=lambda x: x[1], reverse=True)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExactExplainer explainer: 901it [00:13, 25.78it/s]                          \n"
     ]
    }
   ],
   "source": [
    "clf_rf_shap = GeneralClassifier_Shap(clf_rt, outlier_detection=outlier_detection, X=Xtr, y=ytr, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LoanDuration', 0.08396093310336354, 0.2779718140399186),\n",
       " ('Age', 0.057508943987659815, 0.19671331484564517),\n",
       " ('LoanAmount', 0.03662699766295823, 0.13678909653787466),\n",
       " ('Single', 0.021008334734129636, 0.06347488540425911),\n",
       " ('isMale', 0.012080998224669705, 0.08227360496431882),\n",
       " ('LoanRateAsPercentOfIncome', 0.01144972571009471, 0.12564793716935008),\n",
       " ('ForeignWorker', 0.006460803714000895, 5.947448460845439e-05)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = list(zip(Xtr.columns, clf_rf_shap.importances, clf_rf_shap.shap_max))\n",
    "imp.sort(key=lambda x: x[1], reverse=True)\n",
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_tree, individual,\n",
    "                               clf_rt, threshold=threshold,\n",
    "                               max_changes=float('inf'))\n",
    "    lp.build_model()\n",
    "    lp.fit(threads=1)\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_rf_results[i] = {}\n",
    "    lp_rf_results[i]['enum'] = lp\n",
    "    lp_rf_results[i]['indiv'] = individual\n",
    "    lp_rf_results[i]['solution'] = lp.solution#[int(s) if act.variable_type=='int' else float(s) for s, act in zip(pl.solution, action_set)]\n",
    "    lp_rf_results[i]['time'] = lp_time\n",
    "    lp_rf_results[i]['cost'] = criteria.f(lp_rf_results[i]['solution']) if not any(np.isnan(lp_rf_results[i]['solution'])) else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_rf_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    greedy = Greedy(action_set_tree, individual, mapocam_clf_rf_fast, criteria)\n",
    "    greedy.fit()\n",
    "    greedy_time = time.perf_counter()-start\n",
    "    \n",
    "    greedy_rf_results[i] = {}\n",
    "    greedy_rf_results[i]['solution'] = greedy.solution\n",
    "    greedy_rf_results[i]['time'] = greedy_time\n",
    "    greedy_rf_results[i]['cost'] = criteria.f(greedy.solution) if greedy.solution is not None else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 52.48it/s]\n"
     ]
    }
   ],
   "source": [
    "mapocam_rf_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual,\n",
    "                      mapocam_clf_rf, max_changes=float('inf'),\n",
    "                      compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results[i] = {}\n",
    "    mapocam_rf_results[i]['enum'] = mapocam\n",
    "    mapocam_rf_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_rf_results[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual,\n",
    "                      mapocam_clf_rf_fast, max_changes=float('inf'),\n",
    "                      compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_plus[i] = {}\n",
    "    mapocam_rf_results_plus[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_plus[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_rf_results_plus[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_plus[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapocam 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  3%|▎         | 1/35 [00:00<00:09,  3.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 31%|███▏      | 11/35 [00:00<00:00, 33.33it/s]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 49%|████▊     | 17/35 [00:00<00:00, 41.34it/s]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 69%|██████▊   | 24/35 [00:00<00:00, 48.58it/s]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 86%|████████▌ | 30/35 [00:00<00:00, 32.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: [1.29294823]\n",
      "max prob: [0.94747064]\n",
      "max prob: [0.47874238]\n",
      "max prob: [0.60106181]\n",
      "max prob: [0.5155523]\n",
      "max prob: [0.44237677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "100%|██████████| 35/35 [00:01<00:00, 31.78it/s]\n"
     ]
    }
   ],
   "source": [
    "mapocam2_rf_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam = MAPOCAM2(action_set, individual, clf_rf_shap,\n",
    "                      max_changes=float('inf'), compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam2_rf_results[i] = {}\n",
    "    mapocam2_rf_results[i]['enum'] = mapocam\n",
    "    mapocam2_rf_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam2_rf_results[i]['time'] = mapocam_time\n",
    "    mapocam2_rf_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6279486449911929, 1.5361950600035925)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([v[\"time\"] for v in mapocam_rf_results.values() if v[\"solution\"] is not None]), np.sum([v[\"time\"] for v in mapocam2_rf_results.values() if v[\"solution\"] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_costs = np.array([lp_rf_results[i]['cost'] for i in denied_individuals])\n",
    "greedy_rf_costs = np.array([greedy_rf_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_rf_costs = np.array([mapocam_rf_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_rf_costs_plus = np.array([mapocam_rf_results_plus[i]['cost'] for i in denied_individuals])\n",
    "best_costs_rf = np.min([lp_rf_costs, greedy_rf_costs, mapocam_rf_costs, mapocam_rf_costs_plus], axis=0)\n",
    "\n",
    "lp_rf_time = np.array([lp_rf_results[i]['time'] for i in denied_individuals])\n",
    "greedy_rf_time = np.array([greedy_rf_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time = np.array([mapocam_rf_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_plus = np.array([mapocam_rf_results_plus[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_rf_time_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_rf_time)),\n",
    "                'greedy': float(np.mean(greedy_rf_time)),\n",
    "                'mi-trees': float(np.mean(lp_rf_time)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_rf_costs_plus==best_costs_rf)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_rf_costs==best_costs_rf)),\n",
    "               'greedy': float(np.mean(greedy_rf_costs==best_costs_rf)),\n",
    "               'mi-trees': float(np.mean(lp_rf_costs==best_costs_rf)),\n",
    "           },\n",
    "             'Feasible rate':1-float(np.mean(np.isinf(mapocam_rf_costs_plus))),\n",
    "             'Number of combinations': rt_combinations\n",
    "    \n",
    "}\n",
    "save_result(tree_dict, 'german', 'tree', 'MPC cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Pareto enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile vs changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual,\n",
    "                      mapocam_clf_rf, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_pc[i] = {}\n",
    "    mapocam_rf_results_pc[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_pc[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_pc[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_pc_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual,\n",
    "                      mapocam_clf_rf_fast, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_pc_plus[i] = {}\n",
    "    mapocam_rf_results_pc_plus[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_pc_plus[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_pc_plus[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_tree, individual, clf_rt, threshold=threshold,\n",
    "                               max_changes=3, multi_solution=True,\n",
    "                               cost_type='linear', compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    lp.build_model()\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_rf_results_pc[i] = {}\n",
    "    lp_rf_results_pc[i]['enum'] = lp\n",
    "    lp_rf_results_pc[i]['time'] = lp_time\n",
    "    lp_rf_results_pc[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_rf_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    bf = BruteForce(action_set_tree, individual, mapocam_clf_rf_fast, max_changes=3, compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_rf_results_pc[i] = {}\n",
    "    bf_rf_results_pc[i]['enum'] = bf\n",
    "    bf_rf_results_pc[i]['time'] = bf_time\n",
    "    bf_rf_results_pc[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_sols_pc = np.array([lp_rf_results_pc[i]['num'] for i in denied_individuals])\n",
    "brute_rf_sols_pc = np.array([bf_rf_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_rf_sols_pc = np.array([mapocam_rf_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_rf_sols_pc_plus = np.array([mapocam_rf_results_pc_plus[i]['num'] for i in denied_individuals])\n",
    "best_rf_sols_pc = brute_rf_sols_pc\n",
    "\n",
    "lp_rf_time_pc = np.array([lp_rf_results_pc[i]['time'] for i in denied_individuals])\n",
    "brute_rf_time_pc = np.array([bf_rf_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_pc = np.array([mapocam_rf_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_pc_plus = np.array([mapocam_rf_results_pc_plus[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict_pc = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_rf_time_pc_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_rf_time_pc)),\n",
    "                'brute-force': float(np.mean(brute_rf_time_pc)),\n",
    "                'po-mi-trees': float(np.mean(lp_rf_time_pc)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_rf_sols_pc_plus==best_rf_sols_pc)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_rf_sols_pc==best_rf_sols_pc)),\n",
    "               'brute-force': float(np.mean(brute_rf_sols_pc==best_rf_sols_pc)),\n",
    "               'po-mi-trees': float(np.mean(lp_rf_sols_pc==best_rf_sols_pc)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(tree_dict_pc, 'german', 'tree', 'MPC vs. #changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual, mapocam_clf_rf, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_feat[i] = {}\n",
    "    mapocam_rf_results_feat[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_feat[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_feat[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_rf_results_feat_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    mapocam = MAPOCAM(action_set_tree, individual, mapocam_clf_rf_fast, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_rf_results_feat_plus[i] = {}\n",
    "    mapocam_rf_results_feat_plus[i]['enum'] = mapocam\n",
    "    mapocam_rf_results_feat_plus[i]['time'] = mapocam_time\n",
    "    mapocam_rf_results_feat_plus[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_rf_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_tree, individual, clf_rt, threshold=threshold,\n",
    "                               max_changes=3, multi_solution=True,\n",
    "                               cost_type='linear')\n",
    "    lp.build_model()\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_rf_results_feat[i] = {}\n",
    "    lp_rf_results_feat[i]['enum'] = lp\n",
    "    lp_rf_results_feat[i]['time'] = lp_time\n",
    "    lp_rf_results_feat[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_rf_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_rf_fast.fit(individual, action_set_tree)\n",
    "    bf = BruteForce(action_set_tree, individual, mapocam_clf_rf_fast, max_changes=3)\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_rf_results_feat[i] = {}\n",
    "    bf_rf_results_feat[i]['enum'] = bf\n",
    "    bf_rf_results_feat[i]['time'] = bf_time\n",
    "    bf_rf_results_feat[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_rf_sols_feat = np.array([bf_rf_results_feat[i]['num'] for i in denied_individuals])\n",
    "lp_rf_sols_feat = np.array([lp_rf_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_rf_sols_feat = np.array([mapocam_rf_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_rf_sols_feat_plus = np.array([mapocam_rf_results_feat_plus[i]['num'] for i in denied_individuals])\n",
    "best_rf_sols_feat = brute_rf_sols_feat\n",
    "\n",
    "brute_rf_time_feat = np.array([bf_rf_results_feat[i]['time'] for i in denied_individuals])\n",
    "lp_rf_time_feat = np.array([lp_rf_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_feat = np.array([mapocam_rf_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_rf_time_feat_plus = np.array([mapocam_rf_results_feat_plus[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict_feat = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_rf_time_feat_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_rf_time_feat)),\n",
    "                'brute-force': float(np.mean(brute_rf_time_feat)),\n",
    "                'po-mi-trees': float(np.mean(lp_rf_time_feat)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_rf_sols_feat_plus==best_rf_sols_feat)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_rf_sols_feat==best_rf_sols_feat)),\n",
    "               'brute-force': float(np.mean(brute_rf_sols_feat==best_rf_sols_feat)),\n",
    "               'po-mi-trees': float(np.mean(lp_rf_sols_feat==best_rf_sols_feat)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(tree_dict_feat, 'german', 'tree', 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monotone trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble\n",
    "import lightgbm\n",
    "from cfmining.predictors import MonotoneTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotone_constraints = [action.step_direction for action in action_set_base]\n",
    "clf_mt = lightgbm.LGBMClassifier(n_estimators=10, max_depth=10, num_leaves=63,\n",
    "                                 monotone_constraints=monotone_constraints, class_weight='balanced')\n",
    "clf_mt.fit(Xtr, ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing counterfactual parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set_mtree = copy.deepcopy(action_set_base)\n",
    "action_set_mtree.embed_forest(clf_mt)\n",
    "for action in action_set_mtree:\n",
    "    action.flip_direction = action.step_direction\n",
    "\n",
    "print('ActionSet stats')\n",
    "print('Number of actionable features:', sum([action.mutable for action in action_set_mtree]))\n",
    "print('Mean number of actions per feature:', np.mean([len(action._grid)-1 for action in action_set_mtree]))\n",
    "print('Max number of actions per feature:', np.max([len(action._grid)-1 for action in action_set_mtree]))\n",
    "mt_combinations = int(np.prod([len(action._grid) for action in action_set_mtree if action.actionable]))\n",
    "print('Number of combinations:', mt_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.Series(clf_mt.predict_proba(Xts)[:, 1])\n",
    "denied_individuals = scores.loc[lambda s: s < threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percCalc = PercentileCalculator(action_set=action_set_mtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_clf_mt = TreeClassifier(clf_mt, Xtr, ytr, clf_type='lightgbm', threshold=threshold)\n",
    "mapocam_clf_mt_fast = TreeClassifier(clf_mt, Xtr, ytr, clf_type='lightgbm', threshold=threshold, use_predict_max=True)\n",
    "mapocam_clf_mt_mon = MonotoneTree(clf_mt, Xtr, ytr, clf_type='lightgbm', threshold=threshold, use_predict_max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_mt_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_mtree, individual, clf_mt, clf_type='lightgbm', threshold=threshold, max_changes=float('inf'))\n",
    "    lp.build_model()\n",
    "    lp.fit(threads=1)\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_mt_results[i] = {}\n",
    "    lp_mt_results[i]['enum'] = lp\n",
    "    lp_mt_results[i]['indiv'] = individual\n",
    "    lp_mt_results[i]['solution'] = lp.solution#[int(s) if act.variable_type=='int' else float(s) for s, act in zip(pl.solution, action_set)]\n",
    "    lp_mt_results[i]['time'] = lp_time\n",
    "    lp_mt_results[i]['cost'] = criteria.f(lp_mt_results[i]['solution']) if not any(np.isnan(lp_mt_results[i]['solution'])) else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_mt_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    greedy = Greedy(action_set_mtree, individual, mapocam_clf_mt_fast, criteria)\n",
    "    greedy.fit()\n",
    "    greedy_time = time.perf_counter()-start\n",
    "    \n",
    "    greedy_mt_results[i] = {}\n",
    "    greedy_mt_results[i]['solution'] = greedy.solution\n",
    "    greedy_mt_results[i]['time'] = greedy_time\n",
    "    greedy_mt_results[i]['cost'] = criteria.f(greedy.solution) if greedy.solution is not None else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPOCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, \n",
    "                      mapocam_clf_mt, max_changes=float('inf'), \n",
    "                      compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results[i] = {}\n",
    "    mapocam_mt_results[i]['enum'] = mapocam\n",
    "    mapocam_mt_results[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_mt_results[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, \n",
    "                      mapocam_clf_mt_fast, max_changes=float('inf'),\n",
    "                      compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_plus[i] = {}\n",
    "    mapocam_mt_results_plus[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_plus[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_mt_results_plus[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_plus[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_mon = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_mon.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, mapocam_clf_mt_mon, max_changes=float('inf'), compare=criteria)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_mon[i] = {}\n",
    "    mapocam_mt_results_mon[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_mon[i]['solution'] = mapocam.solutions[0] if len(mapocam.solutions)>0 else None\n",
    "    mapocam_mt_results_mon[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_mon[i]['cost'] = criteria.f(mapocam.solutions[0])  if len(mapocam.solutions)>0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_mt_costs = np.array([lp_mt_results[i]['cost'] for i in denied_individuals])\n",
    "greedy_mt_costs = np.array([greedy_mt_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_mt_costs = np.array([mapocam_mt_results[i]['cost'] for i in denied_individuals])\n",
    "mapocam_mt_costs_plus = np.array([mapocam_mt_results_plus[i]['cost'] for i in denied_individuals])\n",
    "mapocam_mt_costs_mon = np.array([mapocam_mt_results_mon[i]['cost'] for i in denied_individuals])\n",
    "best_costs_mt_rf = np.min([lp_mt_costs, greedy_mt_costs, mapocam_mt_costs, mapocam_mt_costs_plus, mapocam_mt_costs_mon], axis=0)\n",
    "\n",
    "lp_mt_time = np.array([lp_mt_results[i]['time'] for i in denied_individuals])\n",
    "greedy_mt_time = np.array([greedy_mt_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time = np.array([mapocam_mt_results[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_plus = np.array([mapocam_mt_results_plus[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_mon = np.array([mapocam_mt_results_mon[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-M': float(np.mean(mapocam_mt_time_mon)),\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_mt_time_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_mt_time)),\n",
    "                'greedy': float(np.mean(greedy_mt_time)),\n",
    "                'mi-trees': float(np.mean(lp_mt_time)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-M':float(np.mean(mapocam_mt_costs_mon==best_costs_mt_rf)),\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_mt_costs_plus==best_costs_mt_rf)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_mt_costs==best_costs_mt_rf)),\n",
    "               'greedy': float(np.mean(greedy_mt_costs==best_costs_mt_rf)),\n",
    "               'mi-trees': float(np.mean(lp_mt_costs==best_costs_mt_rf)),\n",
    "           },\n",
    "             'Feasible rate':1-float(np.mean(np.isinf(mapocam_mt_costs_mon))),\n",
    "             'Number of combinations': mt_combinations\n",
    "    \n",
    "}\n",
    "save_result(tree_dict, 'german', 'monotone-tree', 'MPC cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Pareto enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile vs changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, \n",
    "                      mapocam_clf_mt, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_pc[i] = {}\n",
    "    mapocam_mt_results_pc[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_pc[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_pc[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_pc_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual,\n",
    "                      mapocam_clf_mt_fast, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_pc_plus[i] = {}\n",
    "    mapocam_mt_results_pc_plus[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_pc_plus[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_pc_plus[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_pc_mon = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_mon.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual,\n",
    "                      mapocam_clf_mt_mon, max_changes=3,\n",
    "                      compare=PercentileChangesCriterion(individual, percCalc),\n",
    "                      recursive=False)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_pc_mon[i] = {}\n",
    "    mapocam_mt_results_pc_mon[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_pc_mon[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_pc_mon[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_mt_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_mtree, individual, clf_mt, clf_type='lightgbm', threshold=threshold,\n",
    "                               max_changes=3, multi_solution=True,\n",
    "                               cost_type='linear', compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    lp.build_model()\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_mt_results_pc[i] = {}\n",
    "    lp_mt_results_pc[i]['enum'] = lp\n",
    "    lp_mt_results_pc[i]['time'] = lp_time\n",
    "    lp_mt_results_pc[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_mt_results_pc = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    bf = BruteForce(action_set_mtree, individual, mapocam_clf_mt_fast, max_changes=3, compare=PercentileChangesCriterion(individual, percCalc))\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_mt_results_pc[i] = {}\n",
    "    bf_mt_results_pc[i]['enum'] = bf\n",
    "    bf_mt_results_pc[i]['time'] = bf_time\n",
    "    bf_mt_results_pc[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_mt_sols_pc = np.array([bf_mt_results_pc[i]['num'] for i in denied_individuals])\n",
    "lp_mt_sols_pc = np.array([lp_mt_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_pc = np.array([mapocam_mt_results_pc[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_pc_plus = np.array([mapocam_mt_results_pc_plus[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_pc_mon = np.array([mapocam_mt_results_pc_mon[i]['num'] for i in denied_individuals])\n",
    "best_mt_sols_pc = brute_mt_sols_pc\n",
    "\n",
    "brute_mt_time_pc = np.array([bf_mt_results_pc[i]['time'] for i in denied_individuals])\n",
    "lp_mt_time_pc = np.array([lp_mt_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_pc = np.array([mapocam_mt_results_pc[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_pc_plus = np.array([mapocam_mt_results_pc_plus[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_pc_mon = np.array([mapocam_mt_results_pc_mon[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_tree_dict_pc = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-M': float(np.mean(mapocam_mt_time_pc_mon)),\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_mt_time_pc_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_mt_time_pc)),\n",
    "                'brute-force': float(np.mean(brute_mt_time_pc)),\n",
    "                'po-mi-trees': float(np.mean(lp_mt_time_pc)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-M':float(np.mean(mapocam_mt_sols_pc_plus==mapocam_mt_sols_pc_mon)),\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_mt_sols_pc_plus==best_mt_sols_pc)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_mt_sols_pc==best_mt_sols_pc)),\n",
    "               'brute-force': float(np.mean(brute_mt_sols_pc==best_mt_sols_pc)),\n",
    "               'po-mi-trees': float(np.mean(lp_mt_sols_pc==best_mt_sols_pc)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(mon_tree_dict_pc, 'german', 'monotone-tree', 'MPC vs. #changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, mapocam_clf_mt, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_feat[i] = {}\n",
    "    mapocam_mt_results_feat[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_feat[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_feat[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_feat_plus = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, mapocam_clf_mt_fast, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_feat_plus[i] = {}\n",
    "    mapocam_mt_results_feat_plus[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_feat_plus[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_feat_plus[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapocam_mt_results_feat_mon = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_mon.fit(individual, action_set_mtree)\n",
    "    mapocam = MAPOCAM(action_set_mtree, individual, mapocam_clf_mt_mon, max_changes=3, recursive=True)\n",
    "    mapocam.fit()\n",
    "    mapocam_time = time.perf_counter()-start\n",
    "    \n",
    "    mapocam_mt_results_feat_mon[i] = {}\n",
    "    mapocam_mt_results_feat_mon[i]['enum'] = mapocam\n",
    "    mapocam_mt_results_feat_mon[i]['time'] = mapocam_time\n",
    "    mapocam_mt_results_feat_mon[i]['num'] = len(mapocam.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_mt_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    criteria = PercentileCriterion(individual, percCalc)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    lp = ForestRecourseActions(action_set_mtree, individual, clf_mt, clf_type='lightgbm', threshold=threshold,\n",
    "                               max_changes=3, multi_solution=True,\n",
    "                               cost_type='linear')\n",
    "    lp.build_model()\n",
    "    lp.fit()\n",
    "    lp_time = time.perf_counter()-start\n",
    "    \n",
    "    lp_mt_results_feat[i] = {}\n",
    "    lp_mt_results_feat[i]['enum'] = lp\n",
    "    lp_mt_results_feat[i]['time'] = lp_time\n",
    "    lp_mt_results_feat[i]['num'] = len(lp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_mt_results_feat = {}\n",
    "for i in tqdm(denied_individuals):\n",
    "    individual = Xts.iloc[i].values\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    mapocam_clf_mt_fast.fit(individual, action_set_mtree)\n",
    "    bf = BruteForce(action_set_mtree, individual, mapocam_clf_mt_fast, max_changes=3)\n",
    "    bf.fit()\n",
    "    bf_time = time.perf_counter()-start\n",
    "    \n",
    "    bf_mt_results_feat[i] = {}\n",
    "    bf_mt_results_feat[i]['enum'] = bf\n",
    "    bf_mt_results_feat[i]['time'] = bf_time\n",
    "    bf_mt_results_feat[i]['num'] = len(bf.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_mt_sols_feat = np.array([bf_mt_results_feat[i]['num'] for i in denied_individuals])\n",
    "lp_mt_sols_feat = np.array([lp_mt_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_feat = np.array([mapocam_mt_results_feat[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_feat_plus = np.array([mapocam_mt_results_feat_plus[i]['num'] for i in denied_individuals])\n",
    "mapocam_mt_sols_feat_mon = np.array([mapocam_mt_results_feat_mon[i]['num'] for i in denied_individuals])\n",
    "best_mt_sols_feat = brute_mt_sols_feat\n",
    "\n",
    "brute_mt_time_feat = np.array([bf_mt_results_feat[i]['time'] for i in denied_individuals])\n",
    "lp_mt_time_feat = np.array([lp_mt_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_feat = np.array([mapocam_mt_results_feat[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_feat_plus = np.array([mapocam_mt_results_feat_plus[i]['time'] for i in denied_individuals])\n",
    "mapocam_mt_time_feat_mon = np.array([mapocam_mt_results_feat_mon[i]['time'] for i in denied_individuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feasible rate:', np.mean(best_mt_sols_feat!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_tree_dict_feat = {'Time performance':\n",
    "            {\n",
    "                'MAPOCAM-M': float(np.mean(mapocam_mt_time_feat_mon)),\n",
    "                'MAPOCAM-P': float(np.mean(mapocam_mt_time_feat_plus)),\n",
    "                'MAPOCAM-N': float(np.mean(mapocam_mt_time_feat)),\n",
    "                'brute-force': float(np.mean(brute_mt_time_feat)),\n",
    "                'po-mi-trees': float(np.mean(lp_mt_time_feat)),\n",
    "            },\n",
    "            'Best solution rate':\n",
    "           {\n",
    "               'MAPOCAM-M':float(np.mean(mapocam_mt_sols_feat_mon==best_mt_sols_feat)),\n",
    "               'MAPOCAM-P':float(np.mean(mapocam_mt_sols_feat_plus==best_mt_sols_feat)),\n",
    "               'MAPOCAM-N':float(np.mean(mapocam_mt_sols_feat==best_mt_sols_feat)),\n",
    "               'brute-force': float(np.mean(brute_mt_sols_feat==best_mt_sols_feat)),\n",
    "               'po-mi-trees': float(np.mean(lp_mt_sols_feat==best_mt_sols_feat)),\n",
    "           }\n",
    "    \n",
    "}\n",
    "save_result(mon_tree_dict_feat, 'german', 'monotone-tree', 'feature')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
